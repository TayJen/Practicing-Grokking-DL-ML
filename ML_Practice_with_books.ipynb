{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.30250000000000005 Prediction: 0.25\n",
      "Error: 0.3019502500000001 Prediction: 0.2505\n",
      "Error: 0.30140100000000003 Prediction: 0.251\n",
      "Error: 0.30085225 Prediction: 0.2515\n",
      "Error: 0.30030400000000007 Prediction: 0.252\n",
      "Error: 0.2997562500000001 Prediction: 0.2525\n",
      "Error: 0.29920900000000006 Prediction: 0.253\n",
      "Error: 0.29866224999999996 Prediction: 0.2535\n",
      "Error: 0.29811600000000005 Prediction: 0.254\n",
      "Error: 0.2975702500000001 Prediction: 0.2545\n",
      "Error: 0.29702500000000004 Prediction: 0.255\n",
      "Error: 0.29648025 Prediction: 0.2555\n",
      "Error: 0.29593600000000003 Prediction: 0.256\n",
      "Error: 0.2953922500000001 Prediction: 0.2565\n",
      "Error: 0.294849 Prediction: 0.257\n",
      "Error: 0.29430625 Prediction: 0.2575\n",
      "Error: 0.293764 Prediction: 0.258\n",
      "Error: 0.2932222500000001 Prediction: 0.2585\n",
      "Error: 0.292681 Prediction: 0.259\n",
      "Error: 0.29214025 Prediction: 0.2595\n",
      "Error: 0.2916 Prediction: 0.26\n",
      "Error: 0.2910602500000001 Prediction: 0.2605\n",
      "Error: 0.29052100000000003 Prediction: 0.261\n",
      "Error: 0.28998225 Prediction: 0.2615\n",
      "Error: 0.28944400000000003 Prediction: 0.262\n",
      "Error: 0.2889062500000001 Prediction: 0.2625\n",
      "Error: 0.28836900000000004 Prediction: 0.263\n",
      "Error: 0.28783224999999996 Prediction: 0.2635\n",
      "Error: 0.28729600000000005 Prediction: 0.264\n",
      "Error: 0.2867602500000001 Prediction: 0.2645\n",
      "Error: 0.286225 Prediction: 0.265\n",
      "Error: 0.28569025 Prediction: 0.2655\n",
      "Error: 0.285156 Prediction: 0.266\n",
      "Error: 0.2846222500000001 Prediction: 0.2665\n",
      "Error: 0.28408900000000004 Prediction: 0.267\n",
      "Error: 0.28355624999999995 Prediction: 0.2675\n",
      "Error: 0.28302400000000005 Prediction: 0.268\n",
      "Error: 0.2824922500000001 Prediction: 0.2685\n",
      "Error: 0.281961 Prediction: 0.269\n",
      "Error: 0.28143025 Prediction: 0.2695\n",
      "Error: 0.28090000000000004 Prediction: 0.27\n",
      "Error: 0.2803702500000001 Prediction: 0.2705\n",
      "Error: 0.279841 Prediction: 0.271\n",
      "Error: 0.27931225 Prediction: 0.2715\n",
      "Error: 0.27878400000000003 Prediction: 0.272\n",
      "Error: 0.2782562500000001 Prediction: 0.2725\n",
      "Error: 0.277729 Prediction: 0.273\n",
      "Error: 0.27720225 Prediction: 0.2735\n",
      "Error: 0.27667600000000003 Prediction: 0.274\n",
      "Error: 0.2761502500000001 Prediction: 0.2745\n",
      "Error: 0.275625 Prediction: 0.275\n",
      "Error: 0.27510025 Prediction: 0.2755\n",
      "Error: 0.27457600000000004 Prediction: 0.276\n",
      "Error: 0.27405225000000005 Prediction: 0.2765\n",
      "Error: 0.273529 Prediction: 0.277\n",
      "Error: 0.27300624999999995 Prediction: 0.2775\n",
      "Error: 0.272484 Prediction: 0.278\n",
      "Error: 0.27196225000000007 Prediction: 0.2785\n",
      "Error: 0.27144100000000004 Prediction: 0.279\n",
      "Error: 0.27092025 Prediction: 0.2795\n",
      "Error: 0.27040000000000003 Prediction: 0.28\n",
      "Error: 0.2698802500000001 Prediction: 0.2805\n",
      "Error: 0.269361 Prediction: 0.281\n",
      "Error: 0.26884224999999995 Prediction: 0.28150000000000003\n",
      "Error: 0.268324 Prediction: 0.28200000000000003\n",
      "Error: 0.2678062500000001 Prediction: 0.28250000000000003\n",
      "Error: 0.267289 Prediction: 0.28300000000000003\n",
      "Error: 0.26677224999999993 Prediction: 0.28350000000000003\n",
      "Error: 0.266256 Prediction: 0.28400000000000003\n",
      "Error: 0.26574025000000007 Prediction: 0.28450000000000003\n",
      "Error: 0.265225 Prediction: 0.28500000000000003\n",
      "Error: 0.26471025 Prediction: 0.28550000000000003\n",
      "Error: 0.264196 Prediction: 0.28600000000000003\n",
      "Error: 0.26368225000000006 Prediction: 0.28650000000000003\n",
      "Error: 0.263169 Prediction: 0.28700000000000003\n",
      "Error: 0.26265625 Prediction: 0.28750000000000003\n",
      "Error: 0.262144 Prediction: 0.28800000000000003\n",
      "Error: 0.26163225000000007 Prediction: 0.28850000000000003\n",
      "Error: 0.261121 Prediction: 0.28900000000000003\n",
      "Error: 0.26061024999999993 Prediction: 0.28950000000000004\n",
      "Error: 0.2601 Prediction: 0.29000000000000004\n",
      "Error: 0.2595902500000001 Prediction: 0.29050000000000004\n",
      "Error: 0.259081 Prediction: 0.29100000000000004\n",
      "Error: 0.25857224999999995 Prediction: 0.29150000000000004\n",
      "Error: 0.258064 Prediction: 0.29200000000000004\n",
      "Error: 0.25755625000000004 Prediction: 0.29250000000000004\n",
      "Error: 0.257049 Prediction: 0.29300000000000004\n",
      "Error: 0.25654224999999997 Prediction: 0.29350000000000004\n",
      "Error: 0.256036 Prediction: 0.29400000000000004\n",
      "Error: 0.25553025000000007 Prediction: 0.29450000000000004\n",
      "Error: 0.255025 Prediction: 0.29500000000000004\n",
      "Error: 0.25452024999999995 Prediction: 0.29550000000000004\n",
      "Error: 0.254016 Prediction: 0.29600000000000004\n",
      "Error: 0.25351225000000005 Prediction: 0.29650000000000004\n",
      "Error: 0.253009 Prediction: 0.29700000000000004\n",
      "Error: 0.25250624999999993 Prediction: 0.29750000000000004\n",
      "Error: 0.252004 Prediction: 0.29800000000000004\n",
      "Error: 0.25150225000000004 Prediction: 0.29850000000000004\n",
      "Error: 0.251001 Prediction: 0.29900000000000004\n",
      "Error: 0.2505002499999999 Prediction: 0.29950000000000004\n",
      "Error: 0.25 Prediction: 0.30000000000000004\n",
      "Error: 0.24950025 Prediction: 0.30050000000000004\n",
      "Error: 0.249001 Prediction: 0.30100000000000005\n",
      "Error: 0.24850225 Prediction: 0.30150000000000005\n",
      "Error: 0.248004 Prediction: 0.30200000000000005\n",
      "Error: 0.24750625 Prediction: 0.30250000000000005\n",
      "Error: 0.247009 Prediction: 0.30300000000000005\n",
      "Error: 0.24651225 Prediction: 0.30350000000000005\n",
      "Error: 0.24601599999999998 Prediction: 0.30400000000000005\n",
      "Error: 0.24552025 Prediction: 0.30450000000000005\n",
      "Error: 0.245025 Prediction: 0.30500000000000005\n",
      "Error: 0.24453025 Prediction: 0.30550000000000005\n",
      "Error: 0.244036 Prediction: 0.30600000000000005\n",
      "Error: 0.24354225 Prediction: 0.30650000000000005\n",
      "Error: 0.243049 Prediction: 0.30700000000000005\n",
      "Error: 0.24255625 Prediction: 0.30750000000000005\n",
      "Error: 0.242064 Prediction: 0.30800000000000005\n",
      "Error: 0.24157225 Prediction: 0.30850000000000005\n",
      "Error: 0.241081 Prediction: 0.30900000000000005\n",
      "Error: 0.24059025 Prediction: 0.30950000000000005\n",
      "Error: 0.24009999999999998 Prediction: 0.31000000000000005\n",
      "Error: 0.23961025 Prediction: 0.31050000000000005\n",
      "Error: 0.239121 Prediction: 0.31100000000000005\n",
      "Error: 0.23863225 Prediction: 0.31150000000000005\n",
      "Error: 0.238144 Prediction: 0.31200000000000006\n",
      "Error: 0.23765624999999999 Prediction: 0.31250000000000006\n",
      "Error: 0.237169 Prediction: 0.31300000000000006\n",
      "Error: 0.23668224999999998 Prediction: 0.31350000000000006\n",
      "Error: 0.236196 Prediction: 0.31400000000000006\n",
      "Error: 0.23571024999999998 Prediction: 0.31450000000000006\n",
      "Error: 0.235225 Prediction: 0.31500000000000006\n",
      "Error: 0.23474024999999998 Prediction: 0.31550000000000006\n",
      "Error: 0.234256 Prediction: 0.31600000000000006\n",
      "Error: 0.23377225 Prediction: 0.31650000000000006\n",
      "Error: 0.233289 Prediction: 0.31700000000000006\n",
      "Error: 0.23280625 Prediction: 0.31750000000000006\n",
      "Error: 0.23232399999999997 Prediction: 0.31800000000000006\n",
      "Error: 0.23184224999999997 Prediction: 0.31850000000000006\n",
      "Error: 0.23136099999999998 Prediction: 0.31900000000000006\n",
      "Error: 0.23088024999999998 Prediction: 0.31950000000000006\n",
      "Error: 0.2304 Prediction: 0.32000000000000006\n",
      "Error: 0.22992025 Prediction: 0.32050000000000006\n",
      "Error: 0.22944099999999998 Prediction: 0.32100000000000006\n",
      "Error: 0.22896224999999998 Prediction: 0.32150000000000006\n",
      "Error: 0.228484 Prediction: 0.32200000000000006\n",
      "Error: 0.22800625 Prediction: 0.32250000000000006\n",
      "Error: 0.22752899999999998 Prediction: 0.32300000000000006\n",
      "Error: 0.22705224999999998 Prediction: 0.32350000000000007\n",
      "Error: 0.22657599999999997 Prediction: 0.32400000000000007\n",
      "Error: 0.22610024999999997 Prediction: 0.32450000000000007\n",
      "Error: 0.225625 Prediction: 0.32500000000000007\n",
      "Error: 0.22515024999999997 Prediction: 0.32550000000000007\n",
      "Error: 0.224676 Prediction: 0.32600000000000007\n",
      "Error: 0.22420224999999996 Prediction: 0.32650000000000007\n",
      "Error: 0.22372899999999998 Prediction: 0.32700000000000007\n",
      "Error: 0.22325625 Prediction: 0.32750000000000007\n",
      "Error: 0.22278399999999998 Prediction: 0.32800000000000007\n",
      "Error: 0.22231225 Prediction: 0.32850000000000007\n",
      "Error: 0.22184099999999998 Prediction: 0.32900000000000007\n",
      "Error: 0.22137024999999996 Prediction: 0.32950000000000007\n",
      "Error: 0.22089999999999999 Prediction: 0.33000000000000007\n",
      "Error: 0.22043024999999997 Prediction: 0.33050000000000007\n",
      "Error: 0.21996099999999996 Prediction: 0.33100000000000007\n",
      "Error: 0.21949224999999997 Prediction: 0.3315000000000001\n",
      "Error: 0.21902399999999997 Prediction: 0.3320000000000001\n",
      "Error: 0.21855624999999998 Prediction: 0.3325000000000001\n",
      "Error: 0.21808899999999998 Prediction: 0.3330000000000001\n",
      "Error: 0.21762224999999996 Prediction: 0.3335000000000001\n",
      "Error: 0.21715599999999996 Prediction: 0.3340000000000001\n",
      "Error: 0.21669024999999997 Prediction: 0.3345000000000001\n",
      "Error: 0.21622499999999997 Prediction: 0.3350000000000001\n",
      "Error: 0.21576024999999996 Prediction: 0.3355000000000001\n",
      "Error: 0.21529599999999996 Prediction: 0.3360000000000001\n",
      "Error: 0.21483224999999997 Prediction: 0.3365000000000001\n",
      "Error: 0.21436899999999998 Prediction: 0.3370000000000001\n",
      "Error: 0.21390624999999996 Prediction: 0.3375000000000001\n",
      "Error: 0.21344399999999997 Prediction: 0.3380000000000001\n",
      "Error: 0.21298224999999996 Prediction: 0.3385000000000001\n",
      "Error: 0.21252099999999996 Prediction: 0.3390000000000001\n",
      "Error: 0.21206024999999998 Prediction: 0.3395000000000001\n",
      "Error: 0.21159999999999995 Prediction: 0.3400000000000001\n",
      "Error: 0.21114024999999997 Prediction: 0.3405000000000001\n",
      "Error: 0.21068099999999998 Prediction: 0.3410000000000001\n",
      "Error: 0.21022224999999997 Prediction: 0.3415000000000001\n",
      "Error: 0.20976399999999998 Prediction: 0.3420000000000001\n",
      "Error: 0.20930624999999997 Prediction: 0.3425000000000001\n",
      "Error: 0.20884899999999998 Prediction: 0.3430000000000001\n",
      "Error: 0.20839224999999997 Prediction: 0.3435000000000001\n",
      "Error: 0.20793599999999995 Prediction: 0.3440000000000001\n",
      "Error: 0.20748024999999998 Prediction: 0.3445000000000001\n",
      "Error: 0.20702499999999996 Prediction: 0.3450000000000001\n",
      "Error: 0.20657024999999996 Prediction: 0.3455000000000001\n",
      "Error: 0.20611599999999997 Prediction: 0.3460000000000001\n",
      "Error: 0.20566224999999996 Prediction: 0.3465000000000001\n",
      "Error: 0.20520899999999997 Prediction: 0.3470000000000001\n",
      "Error: 0.20475624999999997 Prediction: 0.3475000000000001\n",
      "Error: 0.20430399999999996 Prediction: 0.3480000000000001\n",
      "Error: 0.20385224999999996 Prediction: 0.3485000000000001\n",
      "Error: 0.20340099999999997 Prediction: 0.3490000000000001\n",
      "Error: 0.20295024999999997 Prediction: 0.3495000000000001\n",
      "Error: 0.20249999999999996 Prediction: 0.3500000000000001\n",
      "Error: 0.20205024999999996 Prediction: 0.3505000000000001\n",
      "Error: 0.20160099999999995 Prediction: 0.3510000000000001\n",
      "Error: 0.20115224999999995 Prediction: 0.3515000000000001\n",
      "Error: 0.20070399999999997 Prediction: 0.3520000000000001\n",
      "Error: 0.20025624999999997 Prediction: 0.3525000000000001\n",
      "Error: 0.19980899999999996 Prediction: 0.3530000000000001\n",
      "Error: 0.19936224999999996 Prediction: 0.3535000000000001\n",
      "Error: 0.19891599999999995 Prediction: 0.3540000000000001\n",
      "Error: 0.19847024999999996 Prediction: 0.3545000000000001\n",
      "Error: 0.19802499999999995 Prediction: 0.3550000000000001\n",
      "Error: 0.19758024999999996 Prediction: 0.3555000000000001\n",
      "Error: 0.19713599999999995 Prediction: 0.3560000000000001\n",
      "Error: 0.19669224999999996 Prediction: 0.3565000000000001\n",
      "Error: 0.19624899999999995 Prediction: 0.3570000000000001\n",
      "Error: 0.19580624999999996 Prediction: 0.3575000000000001\n",
      "Error: 0.19536399999999995 Prediction: 0.3580000000000001\n",
      "Error: 0.19492224999999996 Prediction: 0.3585000000000001\n",
      "Error: 0.19448099999999996 Prediction: 0.3590000000000001\n",
      "Error: 0.19404024999999994 Prediction: 0.3595000000000001\n",
      "Error: 0.19359999999999997 Prediction: 0.3600000000000001\n",
      "Error: 0.19316024999999995 Prediction: 0.3605000000000001\n",
      "Error: 0.19272099999999995 Prediction: 0.3610000000000001\n",
      "Error: 0.19228224999999996 Prediction: 0.3615000000000001\n",
      "Error: 0.19184399999999996 Prediction: 0.3620000000000001\n",
      "Error: 0.19140624999999994 Prediction: 0.3625000000000001\n",
      "Error: 0.19096899999999994 Prediction: 0.3630000000000001\n",
      "Error: 0.19053224999999996 Prediction: 0.3635000000000001\n",
      "Error: 0.19009599999999996 Prediction: 0.3640000000000001\n",
      "Error: 0.18966024999999995 Prediction: 0.3645000000000001\n",
      "Error: 0.18922499999999995 Prediction: 0.3650000000000001\n",
      "Error: 0.18879024999999994 Prediction: 0.3655000000000001\n",
      "Error: 0.18835599999999994 Prediction: 0.3660000000000001\n",
      "Error: 0.18792224999999996 Prediction: 0.3665000000000001\n",
      "Error: 0.18748899999999996 Prediction: 0.3670000000000001\n",
      "Error: 0.18705624999999995 Prediction: 0.3675000000000001\n",
      "Error: 0.18662399999999996 Prediction: 0.3680000000000001\n",
      "Error: 0.18619224999999995 Prediction: 0.3685000000000001\n",
      "Error: 0.18576099999999995 Prediction: 0.3690000000000001\n",
      "Error: 0.18533024999999995 Prediction: 0.3695000000000001\n",
      "Error: 0.18489999999999995 Prediction: 0.3700000000000001\n",
      "Error: 0.18447024999999995 Prediction: 0.3705000000000001\n",
      "Error: 0.18404099999999995 Prediction: 0.3710000000000001\n",
      "Error: 0.18361224999999995 Prediction: 0.3715000000000001\n",
      "Error: 0.18318399999999996 Prediction: 0.3720000000000001\n",
      "Error: 0.18275624999999995 Prediction: 0.3725000000000001\n",
      "Error: 0.18232899999999994 Prediction: 0.3730000000000001\n",
      "Error: 0.18190224999999993 Prediction: 0.3735000000000001\n",
      "Error: 0.18147599999999994 Prediction: 0.3740000000000001\n",
      "Error: 0.18105024999999994 Prediction: 0.3745000000000001\n",
      "Error: 0.18062499999999995 Prediction: 0.3750000000000001\n",
      "Error: 0.18020024999999995 Prediction: 0.3755000000000001\n",
      "Error: 0.17977599999999994 Prediction: 0.3760000000000001\n",
      "Error: 0.17935224999999994 Prediction: 0.3765000000000001\n",
      "Error: 0.17892899999999995 Prediction: 0.3770000000000001\n",
      "Error: 0.17850624999999995 Prediction: 0.3775000000000001\n",
      "Error: 0.17808399999999994 Prediction: 0.3780000000000001\n",
      "Error: 0.17766224999999994 Prediction: 0.3785000000000001\n",
      "Error: 0.17724099999999995 Prediction: 0.3790000000000001\n",
      "Error: 0.17682024999999993 Prediction: 0.3795000000000001\n",
      "Error: 0.17639999999999995 Prediction: 0.3800000000000001\n",
      "Error: 0.17598024999999995 Prediction: 0.3805000000000001\n",
      "Error: 0.17556099999999994 Prediction: 0.3810000000000001\n",
      "Error: 0.17514224999999994 Prediction: 0.3815000000000001\n",
      "Error: 0.17472399999999993 Prediction: 0.3820000000000001\n",
      "Error: 0.17430624999999994 Prediction: 0.3825000000000001\n",
      "Error: 0.17388899999999993 Prediction: 0.3830000000000001\n",
      "Error: 0.17347224999999994 Prediction: 0.3835000000000001\n",
      "Error: 0.17305599999999993 Prediction: 0.3840000000000001\n",
      "Error: 0.17264024999999994 Prediction: 0.3845000000000001\n",
      "Error: 0.17222499999999993 Prediction: 0.3850000000000001\n",
      "Error: 0.17181024999999994 Prediction: 0.3855000000000001\n",
      "Error: 0.17139599999999994 Prediction: 0.3860000000000001\n",
      "Error: 0.17098224999999995 Prediction: 0.3865000000000001\n",
      "Error: 0.17056899999999994 Prediction: 0.3870000000000001\n",
      "Error: 0.17015624999999993 Prediction: 0.3875000000000001\n",
      "Error: 0.16974399999999992 Prediction: 0.3880000000000001\n",
      "Error: 0.16933224999999993 Prediction: 0.3885000000000001\n",
      "Error: 0.16892099999999993 Prediction: 0.3890000000000001\n",
      "Error: 0.16851024999999994 Prediction: 0.3895000000000001\n",
      "Error: 0.16809999999999994 Prediction: 0.3900000000000001\n",
      "Error: 0.16769024999999993 Prediction: 0.3905000000000001\n",
      "Error: 0.16728099999999993 Prediction: 0.3910000000000001\n",
      "Error: 0.16687224999999994 Prediction: 0.3915000000000001\n",
      "Error: 0.16646399999999995 Prediction: 0.3920000000000001\n",
      "Error: 0.16605624999999993 Prediction: 0.3925000000000001\n",
      "Error: 0.16564899999999994 Prediction: 0.3930000000000001\n",
      "Error: 0.16524224999999992 Prediction: 0.3935000000000001\n",
      "Error: 0.16483599999999993 Prediction: 0.39400000000000013\n",
      "Error: 0.16443024999999994 Prediction: 0.39450000000000013\n",
      "Error: 0.16402499999999992 Prediction: 0.39500000000000013\n",
      "Error: 0.16362024999999994 Prediction: 0.39550000000000013\n",
      "Error: 0.16321599999999994 Prediction: 0.39600000000000013\n",
      "Error: 0.16281224999999994 Prediction: 0.39650000000000013\n",
      "Error: 0.16240899999999994 Prediction: 0.39700000000000013\n",
      "Error: 0.16200624999999994 Prediction: 0.39750000000000013\n",
      "Error: 0.16160399999999994 Prediction: 0.39800000000000013\n",
      "Error: 0.16120224999999994 Prediction: 0.39850000000000013\n",
      "Error: 0.16080099999999992 Prediction: 0.39900000000000013\n",
      "Error: 0.16040024999999994 Prediction: 0.39950000000000013\n",
      "Error: 0.15999999999999992 Prediction: 0.40000000000000013\n",
      "Error: 0.15960024999999992 Prediction: 0.40050000000000013\n",
      "Error: 0.15920099999999993 Prediction: 0.40100000000000013\n",
      "Error: 0.15880224999999992 Prediction: 0.40150000000000013\n",
      "Error: 0.15840399999999993 Prediction: 0.40200000000000014\n",
      "Error: 0.15800624999999993 Prediction: 0.40250000000000014\n",
      "Error: 0.15760899999999992 Prediction: 0.40300000000000014\n",
      "Error: 0.15721224999999991 Prediction: 0.40350000000000014\n",
      "Error: 0.15681599999999993 Prediction: 0.40400000000000014\n",
      "Error: 0.15642024999999993 Prediction: 0.40450000000000014\n",
      "Error: 0.1560249999999999 Prediction: 0.40500000000000014\n",
      "Error: 0.15563024999999991 Prediction: 0.40550000000000014\n",
      "Error: 0.15523599999999993 Prediction: 0.40600000000000014\n",
      "Error: 0.15484224999999993 Prediction: 0.40650000000000014\n",
      "Error: 0.15444899999999992 Prediction: 0.40700000000000014\n",
      "Error: 0.15405624999999992 Prediction: 0.40750000000000014\n",
      "Error: 0.1536639999999999 Prediction: 0.40800000000000014\n",
      "Error: 0.15327224999999992 Prediction: 0.40850000000000014\n",
      "Error: 0.15288099999999993 Prediction: 0.40900000000000014\n",
      "Error: 0.1524902499999999 Prediction: 0.40950000000000014\n",
      "Error: 0.15209999999999993 Prediction: 0.41000000000000014\n",
      "Error: 0.15171024999999994 Prediction: 0.41050000000000014\n",
      "Error: 0.15132099999999993 Prediction: 0.41100000000000014\n",
      "Error: 0.15093224999999993 Prediction: 0.41150000000000014\n",
      "Error: 0.15054399999999993 Prediction: 0.41200000000000014\n",
      "Error: 0.15015624999999994 Prediction: 0.41250000000000014\n",
      "Error: 0.14976899999999993 Prediction: 0.41300000000000014\n",
      "Error: 0.1493822499999999 Prediction: 0.41350000000000015\n",
      "Error: 0.14899599999999993 Prediction: 0.41400000000000015\n",
      "Error: 0.14861024999999992 Prediction: 0.41450000000000015\n",
      "Error: 0.1482249999999999 Prediction: 0.41500000000000015\n",
      "Error: 0.14784024999999992 Prediction: 0.41550000000000015\n",
      "Error: 0.14745599999999992 Prediction: 0.41600000000000015\n",
      "Error: 0.14707224999999993 Prediction: 0.41650000000000015\n",
      "Error: 0.14668899999999993 Prediction: 0.41700000000000015\n",
      "Error: 0.14630624999999992 Prediction: 0.41750000000000015\n",
      "Error: 0.14592399999999991 Prediction: 0.41800000000000015\n",
      "Error: 0.14554224999999993 Prediction: 0.41850000000000015\n",
      "Error: 0.14516099999999993 Prediction: 0.41900000000000015\n",
      "Error: 0.14478024999999992 Prediction: 0.41950000000000015\n",
      "Error: 0.14439999999999992 Prediction: 0.42000000000000015\n",
      "Error: 0.1440202499999999 Prediction: 0.42050000000000015\n",
      "Error: 0.1436409999999999 Prediction: 0.42100000000000015\n",
      "Error: 0.14326224999999992 Prediction: 0.42150000000000015\n",
      "Error: 0.14288399999999993 Prediction: 0.42200000000000015\n",
      "Error: 0.14250624999999992 Prediction: 0.42250000000000015\n",
      "Error: 0.14212899999999992 Prediction: 0.42300000000000015\n",
      "Error: 0.1417522499999999 Prediction: 0.42350000000000015\n",
      "Error: 0.14137599999999992 Prediction: 0.42400000000000015\n",
      "Error: 0.1410002499999999 Prediction: 0.42450000000000015\n",
      "Error: 0.14062499999999992 Prediction: 0.42500000000000016\n",
      "Error: 0.1402502499999999 Prediction: 0.42550000000000016\n",
      "Error: 0.13987599999999992 Prediction: 0.42600000000000016\n",
      "Error: 0.1395022499999999 Prediction: 0.42650000000000016\n",
      "Error: 0.13912899999999992 Prediction: 0.42700000000000016\n",
      "Error: 0.13875624999999991 Prediction: 0.42750000000000016\n",
      "Error: 0.13838399999999992 Prediction: 0.42800000000000016\n",
      "Error: 0.13801224999999992 Prediction: 0.42850000000000016\n",
      "Error: 0.1376409999999999 Prediction: 0.42900000000000016\n",
      "Error: 0.13727024999999993 Prediction: 0.42950000000000016\n",
      "Error: 0.1368999999999999 Prediction: 0.43000000000000016\n",
      "Error: 0.1365302499999999 Prediction: 0.43050000000000016\n",
      "Error: 0.13616099999999992 Prediction: 0.43100000000000016\n",
      "Error: 0.13579224999999992 Prediction: 0.43150000000000016\n",
      "Error: 0.1354239999999999 Prediction: 0.43200000000000016\n",
      "Error: 0.1350562499999999 Prediction: 0.43250000000000016\n",
      "Error: 0.13468899999999992 Prediction: 0.43300000000000016\n",
      "Error: 0.13432224999999992 Prediction: 0.43350000000000016\n",
      "Error: 0.1339559999999999 Prediction: 0.43400000000000016\n",
      "Error: 0.1335902499999999 Prediction: 0.43450000000000016\n",
      "Error: 0.1332249999999999 Prediction: 0.43500000000000016\n",
      "Error: 0.1328602499999999 Prediction: 0.43550000000000016\n",
      "Error: 0.13249599999999992 Prediction: 0.43600000000000017\n",
      "Error: 0.13213224999999992 Prediction: 0.43650000000000017\n",
      "Error: 0.13176899999999991 Prediction: 0.43700000000000017\n",
      "Error: 0.13140624999999992 Prediction: 0.43750000000000017\n",
      "Error: 0.1310439999999999 Prediction: 0.43800000000000017\n",
      "Error: 0.13068224999999992 Prediction: 0.43850000000000017\n",
      "Error: 0.1303209999999999 Prediction: 0.43900000000000017\n",
      "Error: 0.12996024999999992 Prediction: 0.43950000000000017\n",
      "Error: 0.1295999999999999 Prediction: 0.44000000000000017\n",
      "Error: 0.12924024999999992 Prediction: 0.44050000000000017\n",
      "Error: 0.1288809999999999 Prediction: 0.44100000000000017\n",
      "Error: 0.12852224999999992 Prediction: 0.44150000000000017\n",
      "Error: 0.12816399999999992 Prediction: 0.44200000000000017\n",
      "Error: 0.1278062499999999 Prediction: 0.44250000000000017\n",
      "Error: 0.1274489999999999 Prediction: 0.44300000000000017\n",
      "Error: 0.1270922499999999 Prediction: 0.44350000000000017\n",
      "Error: 0.1267359999999999 Prediction: 0.4440000000000002\n",
      "Error: 0.12638024999999992 Prediction: 0.4445000000000002\n",
      "Error: 0.12602499999999991 Prediction: 0.4450000000000002\n",
      "Error: 0.1256702499999999 Prediction: 0.4455000000000002\n",
      "Error: 0.1253159999999999 Prediction: 0.4460000000000002\n",
      "Error: 0.12496224999999991 Prediction: 0.4465000000000002\n",
      "Error: 0.12460899999999991 Prediction: 0.4470000000000002\n",
      "Error: 0.1242562499999999 Prediction: 0.4475000000000002\n",
      "Error: 0.1239039999999999 Prediction: 0.4480000000000002\n",
      "Error: 0.1235522499999999 Prediction: 0.4485000000000002\n",
      "Error: 0.12320099999999991 Prediction: 0.4490000000000002\n",
      "Error: 0.12285024999999991 Prediction: 0.4495000000000002\n",
      "Error: 0.1224999999999999 Prediction: 0.4500000000000002\n",
      "Error: 0.1221502499999999 Prediction: 0.4505000000000002\n",
      "Error: 0.12180099999999991 Prediction: 0.4510000000000002\n",
      "Error: 0.1214522499999999 Prediction: 0.4515000000000002\n",
      "Error: 0.1211039999999999 Prediction: 0.4520000000000002\n",
      "Error: 0.12075624999999991 Prediction: 0.4525000000000002\n",
      "Error: 0.1204089999999999 Prediction: 0.4530000000000002\n",
      "Error: 0.12006224999999991 Prediction: 0.4535000000000002\n",
      "Error: 0.1197159999999999 Prediction: 0.4540000000000002\n",
      "Error: 0.1193702499999999 Prediction: 0.4545000000000002\n",
      "Error: 0.11902499999999991 Prediction: 0.4550000000000002\n",
      "Error: 0.1186802499999999 Prediction: 0.4555000000000002\n",
      "Error: 0.1183359999999999 Prediction: 0.4560000000000002\n",
      "Error: 0.11799224999999991 Prediction: 0.4565000000000002\n",
      "Error: 0.1176489999999999 Prediction: 0.4570000000000002\n",
      "Error: 0.1173062499999999 Prediction: 0.4575000000000002\n",
      "Error: 0.1169639999999999 Prediction: 0.4580000000000002\n",
      "Error: 0.1166222499999999 Prediction: 0.4585000000000002\n",
      "Error: 0.1162809999999999 Prediction: 0.4590000000000002\n",
      "Error: 0.1159402499999999 Prediction: 0.4595000000000002\n",
      "Error: 0.1155999999999999 Prediction: 0.4600000000000002\n",
      "Error: 0.1152602499999999 Prediction: 0.4605000000000002\n",
      "Error: 0.1149209999999999 Prediction: 0.4610000000000002\n",
      "Error: 0.1145822499999999 Prediction: 0.4615000000000002\n",
      "Error: 0.1142439999999999 Prediction: 0.4620000000000002\n",
      "Error: 0.1139062499999999 Prediction: 0.4625000000000002\n",
      "Error: 0.1135689999999999 Prediction: 0.4630000000000002\n",
      "Error: 0.1132322499999999 Prediction: 0.4635000000000002\n",
      "Error: 0.1128959999999999 Prediction: 0.4640000000000002\n",
      "Error: 0.1125602499999999 Prediction: 0.4645000000000002\n",
      "Error: 0.11222499999999991 Prediction: 0.4650000000000002\n",
      "Error: 0.1118902499999999 Prediction: 0.4655000000000002\n",
      "Error: 0.1115559999999999 Prediction: 0.4660000000000002\n",
      "Error: 0.1112222499999999 Prediction: 0.4665000000000002\n",
      "Error: 0.1108889999999999 Prediction: 0.4670000000000002\n",
      "Error: 0.1105562499999999 Prediction: 0.4675000000000002\n",
      "Error: 0.1102239999999999 Prediction: 0.4680000000000002\n",
      "Error: 0.1098922499999999 Prediction: 0.4685000000000002\n",
      "Error: 0.1095609999999999 Prediction: 0.4690000000000002\n",
      "Error: 0.1092302499999999 Prediction: 0.4695000000000002\n",
      "Error: 0.1088999999999999 Prediction: 0.4700000000000002\n",
      "Error: 0.1085702499999999 Prediction: 0.4705000000000002\n",
      "Error: 0.1082409999999999 Prediction: 0.4710000000000002\n",
      "Error: 0.1079122499999999 Prediction: 0.4715000000000002\n",
      "Error: 0.1075839999999999 Prediction: 0.4720000000000002\n",
      "Error: 0.1072562499999999 Prediction: 0.4725000000000002\n",
      "Error: 0.1069289999999999 Prediction: 0.4730000000000002\n",
      "Error: 0.1066022499999999 Prediction: 0.4735000000000002\n",
      "Error: 0.1062759999999999 Prediction: 0.4740000000000002\n",
      "Error: 0.1059502499999999 Prediction: 0.4745000000000002\n",
      "Error: 0.1056249999999999 Prediction: 0.4750000000000002\n",
      "Error: 0.1053002499999999 Prediction: 0.4755000000000002\n",
      "Error: 0.1049759999999999 Prediction: 0.4760000000000002\n",
      "Error: 0.1046522499999999 Prediction: 0.4765000000000002\n",
      "Error: 0.1043289999999999 Prediction: 0.4770000000000002\n",
      "Error: 0.1040062499999999 Prediction: 0.4775000000000002\n",
      "Error: 0.1036839999999999 Prediction: 0.4780000000000002\n",
      "Error: 0.10336224999999989 Prediction: 0.4785000000000002\n",
      "Error: 0.1030409999999999 Prediction: 0.4790000000000002\n",
      "Error: 0.1027202499999999 Prediction: 0.4795000000000002\n",
      "Error: 0.1023999999999999 Prediction: 0.4800000000000002\n",
      "Error: 0.1020802499999999 Prediction: 0.4805000000000002\n",
      "Error: 0.1017609999999999 Prediction: 0.4810000000000002\n",
      "Error: 0.1014422499999999 Prediction: 0.4815000000000002\n",
      "Error: 0.1011239999999999 Prediction: 0.4820000000000002\n",
      "Error: 0.1008062499999999 Prediction: 0.4825000000000002\n",
      "Error: 0.1004889999999999 Prediction: 0.4830000000000002\n",
      "Error: 0.1001722499999999 Prediction: 0.4835000000000002\n",
      "Error: 0.0998559999999999 Prediction: 0.4840000000000002\n",
      "Error: 0.0995402499999999 Prediction: 0.4845000000000002\n",
      "Error: 0.0992249999999999 Prediction: 0.4850000000000002\n",
      "Error: 0.0989102499999999 Prediction: 0.4855000000000002\n",
      "Error: 0.09859599999999989 Prediction: 0.4860000000000002\n",
      "Error: 0.09828224999999989 Prediction: 0.4865000000000002\n",
      "Error: 0.09796899999999989 Prediction: 0.4870000000000002\n",
      "Error: 0.0976562499999999 Prediction: 0.4875000000000002\n",
      "Error: 0.09734399999999989 Prediction: 0.4880000000000002\n",
      "Error: 0.09703224999999989 Prediction: 0.4885000000000002\n",
      "Error: 0.09672099999999989 Prediction: 0.4890000000000002\n",
      "Error: 0.09641024999999989 Prediction: 0.4895000000000002\n",
      "Error: 0.0960999999999999 Prediction: 0.4900000000000002\n",
      "Error: 0.0957902499999999 Prediction: 0.4905000000000002\n",
      "Error: 0.0954809999999999 Prediction: 0.4910000000000002\n",
      "Error: 0.09517224999999989 Prediction: 0.4915000000000002\n",
      "Error: 0.09486399999999989 Prediction: 0.4920000000000002\n",
      "Error: 0.0945562499999999 Prediction: 0.4925000000000002\n",
      "Error: 0.09424899999999989 Prediction: 0.4930000000000002\n",
      "Error: 0.0939422499999999 Prediction: 0.4935000000000002\n",
      "Error: 0.0936359999999999 Prediction: 0.4940000000000002\n",
      "Error: 0.09333024999999989 Prediction: 0.4945000000000002\n",
      "Error: 0.0930249999999999 Prediction: 0.4950000000000002\n",
      "Error: 0.09272024999999989 Prediction: 0.4955000000000002\n",
      "Error: 0.0924159999999999 Prediction: 0.4960000000000002\n",
      "Error: 0.0921122499999999 Prediction: 0.4965000000000002\n",
      "Error: 0.09180899999999989 Prediction: 0.4970000000000002\n",
      "Error: 0.0915062499999999 Prediction: 0.4975000000000002\n",
      "Error: 0.0912039999999999 Prediction: 0.4980000000000002\n",
      "Error: 0.09090224999999989 Prediction: 0.4985000000000002\n",
      "Error: 0.09060099999999989 Prediction: 0.4990000000000002\n",
      "Error: 0.09030024999999989 Prediction: 0.4995000000000002\n",
      "Error: 0.0899999999999999 Prediction: 0.5000000000000002\n",
      "Error: 0.08970024999999993 Prediction: 0.5005000000000002\n",
      "Error: 0.08940099999999995 Prediction: 0.5010000000000001\n",
      "Error: 0.08910225 Prediction: 0.5015000000000001\n",
      "Error: 0.08880400000000002 Prediction: 0.502\n",
      "Error: 0.08850625000000006 Prediction: 0.5025\n",
      "Error: 0.08820900000000009 Prediction: 0.5029999999999999\n",
      "Error: 0.08791225000000012 Prediction: 0.5034999999999998\n",
      "Error: 0.08761600000000015 Prediction: 0.5039999999999998\n",
      "Error: 0.08732025000000018 Prediction: 0.5044999999999997\n",
      "Error: 0.08702500000000021 Prediction: 0.5049999999999997\n",
      "Error: 0.08673025000000026 Prediction: 0.5054999999999996\n",
      "Error: 0.08643600000000029 Prediction: 0.5059999999999996\n",
      "Error: 0.08614225000000032 Prediction: 0.5064999999999995\n",
      "Error: 0.08584900000000034 Prediction: 0.5069999999999995\n",
      "Error: 0.08555625000000038 Prediction: 0.5074999999999994\n",
      "Error: 0.08526400000000041 Prediction: 0.5079999999999993\n",
      "Error: 0.08497225000000044 Prediction: 0.5084999999999993\n",
      "Error: 0.08468100000000048 Prediction: 0.5089999999999992\n",
      "Error: 0.0843902500000005 Prediction: 0.5094999999999992\n",
      "Error: 0.08410000000000054 Prediction: 0.5099999999999991\n",
      "Error: 0.08381025000000057 Prediction: 0.5104999999999991\n",
      "Error: 0.0835210000000006 Prediction: 0.510999999999999\n",
      "Error: 0.08323225000000063 Prediction: 0.511499999999999\n",
      "Error: 0.08294400000000066 Prediction: 0.5119999999999989\n",
      "Error: 0.0826562500000007 Prediction: 0.5124999999999988\n",
      "Error: 0.08236900000000072 Prediction: 0.5129999999999988\n",
      "Error: 0.08208225000000074 Prediction: 0.5134999999999987\n",
      "Error: 0.08179600000000078 Prediction: 0.5139999999999987\n",
      "Error: 0.08151025000000081 Prediction: 0.5144999999999986\n",
      "Error: 0.08122500000000084 Prediction: 0.5149999999999986\n",
      "Error: 0.08094025000000087 Prediction: 0.5154999999999985\n",
      "Error: 0.0806560000000009 Prediction: 0.5159999999999985\n",
      "Error: 0.08037225000000094 Prediction: 0.5164999999999984\n",
      "Error: 0.08008900000000096 Prediction: 0.5169999999999983\n",
      "Error: 0.079806250000001 Prediction: 0.5174999999999983\n",
      "Error: 0.07952400000000102 Prediction: 0.5179999999999982\n",
      "Error: 0.07924225000000104 Prediction: 0.5184999999999982\n",
      "Error: 0.07896100000000107 Prediction: 0.5189999999999981\n",
      "Error: 0.0786802500000011 Prediction: 0.5194999999999981\n",
      "Error: 0.07840000000000114 Prediction: 0.519999999999998\n",
      "Error: 0.07812025000000117 Prediction: 0.520499999999998\n",
      "Error: 0.07784100000000119 Prediction: 0.5209999999999979\n",
      "Error: 0.07756225000000122 Prediction: 0.5214999999999979\n",
      "Error: 0.07728400000000125 Prediction: 0.5219999999999978\n",
      "Error: 0.07700625000000128 Prediction: 0.5224999999999977\n",
      "Error: 0.07672900000000131 Prediction: 0.5229999999999977\n",
      "Error: 0.07645225000000133 Prediction: 0.5234999999999976\n",
      "Error: 0.07617600000000137 Prediction: 0.5239999999999976\n",
      "Error: 0.07590025000000139 Prediction: 0.5244999999999975\n",
      "Error: 0.07562500000000141 Prediction: 0.5249999999999975\n",
      "Error: 0.07535025000000145 Prediction: 0.5254999999999974\n",
      "Error: 0.07507600000000147 Prediction: 0.5259999999999974\n",
      "Error: 0.0748022500000015 Prediction: 0.5264999999999973\n",
      "Error: 0.07452900000000152 Prediction: 0.5269999999999972\n",
      "Error: 0.07425625000000155 Prediction: 0.5274999999999972\n",
      "Error: 0.07398400000000158 Prediction: 0.5279999999999971\n",
      "Error: 0.0737122500000016 Prediction: 0.5284999999999971\n",
      "Error: 0.07344100000000163 Prediction: 0.528999999999997\n",
      "Error: 0.07317025000000166 Prediction: 0.529499999999997\n",
      "Error: 0.07290000000000169 Prediction: 0.5299999999999969\n",
      "Error: 0.07263025000000171 Prediction: 0.5304999999999969\n",
      "Error: 0.07236100000000174 Prediction: 0.5309999999999968\n",
      "Error: 0.07209225000000177 Prediction: 0.5314999999999968\n",
      "Error: 0.07182400000000179 Prediction: 0.5319999999999967\n",
      "Error: 0.07155625000000182 Prediction: 0.5324999999999966\n",
      "Error: 0.07128900000000185 Prediction: 0.5329999999999966\n",
      "Error: 0.07102225000000187 Prediction: 0.5334999999999965\n",
      "Error: 0.0707560000000019 Prediction: 0.5339999999999965\n",
      "Error: 0.07049025000000192 Prediction: 0.5344999999999964\n",
      "Error: 0.07022500000000195 Prediction: 0.5349999999999964\n",
      "Error: 0.06996025000000197 Prediction: 0.5354999999999963\n",
      "Error: 0.069696000000002 Prediction: 0.5359999999999963\n",
      "Error: 0.06943225000000203 Prediction: 0.5364999999999962\n",
      "Error: 0.06916900000000205 Prediction: 0.5369999999999961\n",
      "Error: 0.06890625000000207 Prediction: 0.5374999999999961\n",
      "Error: 0.0686440000000021 Prediction: 0.537999999999996\n",
      "Error: 0.06838225000000213 Prediction: 0.538499999999996\n",
      "Error: 0.06812100000000215 Prediction: 0.5389999999999959\n",
      "Error: 0.06786025000000218 Prediction: 0.5394999999999959\n",
      "Error: 0.0676000000000022 Prediction: 0.5399999999999958\n",
      "Error: 0.06734025000000222 Prediction: 0.5404999999999958\n",
      "Error: 0.06708100000000225 Prediction: 0.5409999999999957\n",
      "Error: 0.06682225000000228 Prediction: 0.5414999999999957\n",
      "Error: 0.0665640000000023 Prediction: 0.5419999999999956\n",
      "Error: 0.06630625000000231 Prediction: 0.5424999999999955\n",
      "Error: 0.06604900000000234 Prediction: 0.5429999999999955\n",
      "Error: 0.06579225000000237 Prediction: 0.5434999999999954\n",
      "Error: 0.06553600000000238 Prediction: 0.5439999999999954\n",
      "Error: 0.06528025000000241 Prediction: 0.5444999999999953\n",
      "Error: 0.06502500000000244 Prediction: 0.5449999999999953\n",
      "Error: 0.06477025000000246 Prediction: 0.5454999999999952\n",
      "Error: 0.06451600000000249 Prediction: 0.5459999999999952\n",
      "Error: 0.0642622500000025 Prediction: 0.5464999999999951\n",
      "Error: 0.06400900000000254 Prediction: 0.546999999999995\n",
      "Error: 0.06375625000000255 Prediction: 0.547499999999995\n",
      "Error: 0.06350400000000257 Prediction: 0.5479999999999949\n",
      "Error: 0.06325225000000259 Prediction: 0.5484999999999949\n",
      "Error: 0.06300100000000262 Prediction: 0.5489999999999948\n",
      "Error: 0.06275025000000264 Prediction: 0.5494999999999948\n",
      "Error: 0.06250000000000266 Prediction: 0.5499999999999947\n",
      "Error: 0.062250250000002685 Prediction: 0.5504999999999947\n",
      "Error: 0.06200100000000271 Prediction: 0.5509999999999946\n",
      "Error: 0.06175225000000273 Prediction: 0.5514999999999946\n",
      "Error: 0.06150400000000275 Prediction: 0.5519999999999945\n",
      "Error: 0.061256250000002774 Prediction: 0.5524999999999944\n",
      "Error: 0.0610090000000028 Prediction: 0.5529999999999944\n",
      "Error: 0.060762250000002814 Prediction: 0.5534999999999943\n",
      "Error: 0.06051600000000284 Prediction: 0.5539999999999943\n",
      "Error: 0.06027025000000286 Prediction: 0.5544999999999942\n",
      "Error: 0.06002500000000288 Prediction: 0.5549999999999942\n",
      "Error: 0.0597802500000029 Prediction: 0.5554999999999941\n",
      "Error: 0.05953600000000292 Prediction: 0.555999999999994\n",
      "Error: 0.05929225000000295 Prediction: 0.556499999999994\n",
      "Error: 0.05904900000000297 Prediction: 0.5569999999999939\n",
      "Error: 0.05880625000000299 Prediction: 0.5574999999999939\n",
      "Error: 0.058564000000003 Prediction: 0.5579999999999938\n",
      "Error: 0.058322250000003024 Prediction: 0.5584999999999938\n",
      "Error: 0.05808100000000305 Prediction: 0.5589999999999937\n",
      "Error: 0.05784025000000307 Prediction: 0.5594999999999937\n",
      "Error: 0.057600000000003086 Prediction: 0.5599999999999936\n",
      "Error: 0.0573602500000031 Prediction: 0.5604999999999936\n",
      "Error: 0.05712100000000313 Prediction: 0.5609999999999935\n",
      "Error: 0.056882250000003146 Prediction: 0.5614999999999934\n",
      "Error: 0.056644000000003164 Prediction: 0.5619999999999934\n",
      "Error: 0.05640625000000318 Prediction: 0.5624999999999933\n",
      "Error: 0.0561690000000032 Prediction: 0.5629999999999933\n",
      "Error: 0.05593225000000322 Prediction: 0.5634999999999932\n",
      "Error: 0.05569600000000324 Prediction: 0.5639999999999932\n",
      "Error: 0.055460250000003264 Prediction: 0.5644999999999931\n",
      "Error: 0.05522500000000328 Prediction: 0.5649999999999931\n",
      "Error: 0.0549902500000033 Prediction: 0.565499999999993\n",
      "Error: 0.054756000000003316 Prediction: 0.565999999999993\n",
      "Error: 0.05452225000000334 Prediction: 0.5664999999999929\n",
      "Error: 0.054289000000003355 Prediction: 0.5669999999999928\n",
      "Error: 0.05405625000000337 Prediction: 0.5674999999999928\n",
      "Error: 0.05382400000000339 Prediction: 0.5679999999999927\n",
      "Error: 0.05359225000000341 Prediction: 0.5684999999999927\n",
      "Error: 0.053361000000003427 Prediction: 0.5689999999999926\n",
      "Error: 0.053130250000003446 Prediction: 0.5694999999999926\n",
      "Error: 0.052900000000003465 Prediction: 0.5699999999999925\n",
      "Error: 0.052670250000003485 Prediction: 0.5704999999999925\n",
      "Error: 0.0524410000000035 Prediction: 0.5709999999999924\n",
      "Error: 0.05221225000000352 Prediction: 0.5714999999999923\n",
      "Error: 0.051984000000003534 Prediction: 0.5719999999999923\n",
      "Error: 0.05175625000000355 Prediction: 0.5724999999999922\n",
      "Error: 0.05152900000000357 Prediction: 0.5729999999999922\n",
      "Error: 0.05130225000000359 Prediction: 0.5734999999999921\n",
      "Error: 0.051076000000003605 Prediction: 0.5739999999999921\n",
      "Error: 0.05085025000000362 Prediction: 0.574499999999992\n",
      "Error: 0.05062500000000364 Prediction: 0.574999999999992\n",
      "Error: 0.05040025000000365 Prediction: 0.5754999999999919\n",
      "Error: 0.05017600000000367 Prediction: 0.5759999999999919\n",
      "Error: 0.04995225000000369 Prediction: 0.5764999999999918\n",
      "Error: 0.0497290000000037 Prediction: 0.5769999999999917\n",
      "Error: 0.04950625000000372 Prediction: 0.5774999999999917\n",
      "Error: 0.049284000000003735 Prediction: 0.5779999999999916\n",
      "Error: 0.04906225000000375 Prediction: 0.5784999999999916\n",
      "Error: 0.04884100000000377 Prediction: 0.5789999999999915\n",
      "Error: 0.048620250000003785 Prediction: 0.5794999999999915\n",
      "Error: 0.0484000000000038 Prediction: 0.5799999999999914\n",
      "Error: 0.04818025000000382 Prediction: 0.5804999999999914\n",
      "Error: 0.04796100000000383 Prediction: 0.5809999999999913\n",
      "Error: 0.047742250000003844 Prediction: 0.5814999999999912\n",
      "Error: 0.04752400000000386 Prediction: 0.5819999999999912\n",
      "Error: 0.04730625000000387 Prediction: 0.5824999999999911\n",
      "Error: 0.04708900000000389 Prediction: 0.5829999999999911\n",
      "Error: 0.046872250000003904 Prediction: 0.583499999999991\n",
      "Error: 0.04665600000000392 Prediction: 0.583999999999991\n",
      "Error: 0.04644025000000394 Prediction: 0.5844999999999909\n",
      "Error: 0.04622500000000395 Prediction: 0.5849999999999909\n",
      "Error: 0.046010250000003965 Prediction: 0.5854999999999908\n",
      "Error: 0.04579600000000398 Prediction: 0.5859999999999908\n",
      "Error: 0.045582250000003995 Prediction: 0.5864999999999907\n",
      "Error: 0.045369000000004 Prediction: 0.5869999999999906\n",
      "Error: 0.04515625000000402 Prediction: 0.5874999999999906\n",
      "Error: 0.044944000000004036 Prediction: 0.5879999999999905\n",
      "Error: 0.04473225000000405 Prediction: 0.5884999999999905\n",
      "Error: 0.044521000000004064 Prediction: 0.5889999999999904\n",
      "Error: 0.044310250000004076 Prediction: 0.5894999999999904\n",
      "Error: 0.04410000000000409 Prediction: 0.5899999999999903\n",
      "Error: 0.0438902500000041 Prediction: 0.5904999999999903\n",
      "Error: 0.04368100000000411 Prediction: 0.5909999999999902\n",
      "Error: 0.043472250000004126 Prediction: 0.5914999999999901\n",
      "Error: 0.04326400000000414 Prediction: 0.5919999999999901\n",
      "Error: 0.043056250000004154 Prediction: 0.59249999999999\n",
      "Error: 0.04284900000000417 Prediction: 0.59299999999999\n",
      "Error: 0.04264225000000418 Prediction: 0.5934999999999899\n",
      "Error: 0.04243600000000419 Prediction: 0.5939999999999899\n",
      "Error: 0.0422302500000042 Prediction: 0.5944999999999898\n",
      "Error: 0.04202500000000422 Prediction: 0.5949999999999898\n",
      "Error: 0.04182025000000423 Prediction: 0.5954999999999897\n",
      "Error: 0.04161600000000424 Prediction: 0.5959999999999896\n",
      "Error: 0.04141225000000425 Prediction: 0.5964999999999896\n",
      "Error: 0.04120900000000426 Prediction: 0.5969999999999895\n",
      "Error: 0.041006250000004275 Prediction: 0.5974999999999895\n",
      "Error: 0.04080400000000429 Prediction: 0.5979999999999894\n",
      "Error: 0.0406022500000043 Prediction: 0.5984999999999894\n",
      "Error: 0.04040100000000431 Prediction: 0.5989999999999893\n",
      "Error: 0.04020025000000432 Prediction: 0.5994999999999893\n",
      "Error: 0.04000000000000434 Prediction: 0.5999999999999892\n",
      "Error: 0.039800250000004346 Prediction: 0.6004999999999892\n",
      "Error: 0.039601000000004355 Prediction: 0.6009999999999891\n",
      "Error: 0.039402250000004364 Prediction: 0.601499999999989\n",
      "Error: 0.03920400000000438 Prediction: 0.601999999999989\n",
      "Error: 0.03900625000000439 Prediction: 0.6024999999999889\n",
      "Error: 0.0388090000000044 Prediction: 0.6029999999999889\n",
      "Error: 0.03861225000000441 Prediction: 0.6034999999999888\n",
      "Error: 0.03841600000000442 Prediction: 0.6039999999999888\n",
      "Error: 0.03822025000000443 Prediction: 0.6044999999999887\n",
      "Error: 0.038025000000004444 Prediction: 0.6049999999999887\n",
      "Error: 0.03783025000000445 Prediction: 0.6054999999999886\n",
      "Error: 0.03763600000000446 Prediction: 0.6059999999999885\n",
      "Error: 0.03744225000000447 Prediction: 0.6064999999999885\n",
      "Error: 0.03724900000000448 Prediction: 0.6069999999999884\n",
      "Error: 0.03705625000000449 Prediction: 0.6074999999999884\n",
      "Error: 0.0368640000000045 Prediction: 0.6079999999999883\n",
      "Error: 0.03667225000000451 Prediction: 0.6084999999999883\n",
      "Error: 0.03648100000000452 Prediction: 0.6089999999999882\n",
      "Error: 0.03629025000000453 Prediction: 0.6094999999999882\n",
      "Error: 0.03610000000000454 Prediction: 0.6099999999999881\n",
      "Error: 0.03591025000000454 Prediction: 0.610499999999988\n",
      "Error: 0.035721000000004555 Prediction: 0.610999999999988\n",
      "Error: 0.03553225000000456 Prediction: 0.6114999999999879\n",
      "Error: 0.03534400000000457 Prediction: 0.6119999999999879\n",
      "Error: 0.03515625000000458 Prediction: 0.6124999999999878\n",
      "Error: 0.03496900000000459 Prediction: 0.6129999999999878\n",
      "Error: 0.034782250000004594 Prediction: 0.6134999999999877\n",
      "Error: 0.0345960000000046 Prediction: 0.6139999999999877\n",
      "Error: 0.03441025000000461 Prediction: 0.6144999999999876\n",
      "Error: 0.03422500000000462 Prediction: 0.6149999999999876\n",
      "Error: 0.03404025000000463 Prediction: 0.6154999999999875\n",
      "Error: 0.03385600000000464 Prediction: 0.6159999999999874\n",
      "Error: 0.03367225000000464 Prediction: 0.6164999999999874\n",
      "Error: 0.033489000000004654 Prediction: 0.6169999999999873\n",
      "Error: 0.03330625000000466 Prediction: 0.6174999999999873\n",
      "Error: 0.033124000000004664 Prediction: 0.6179999999999872\n",
      "Error: 0.032942250000004676 Prediction: 0.6184999999999872\n",
      "Error: 0.03276100000000468 Prediction: 0.6189999999999871\n",
      "Error: 0.03258025000000469 Prediction: 0.6194999999999871\n",
      "Error: 0.032400000000004696 Prediction: 0.619999999999987\n",
      "Error: 0.0322202500000047 Prediction: 0.620499999999987\n",
      "Error: 0.032041000000004705 Prediction: 0.6209999999999869\n",
      "Error: 0.03186225000000471 Prediction: 0.6214999999999868\n",
      "Error: 0.03168400000000472 Prediction: 0.6219999999999868\n",
      "Error: 0.031506250000004725 Prediction: 0.6224999999999867\n",
      "Error: 0.031329000000004735 Prediction: 0.6229999999999867\n",
      "Error: 0.03115225000000474 Prediction: 0.6234999999999866\n",
      "Error: 0.030976000000004746 Prediction: 0.6239999999999866\n",
      "Error: 0.03080025000000475 Prediction: 0.6244999999999865\n",
      "Error: 0.030625000000004756 Prediction: 0.6249999999999865\n",
      "Error: 0.03045025000000476 Prediction: 0.6254999999999864\n",
      "Error: 0.030276000000004768 Prediction: 0.6259999999999863\n",
      "Error: 0.03010225000000477 Prediction: 0.6264999999999863\n",
      "Error: 0.029929000000004778 Prediction: 0.6269999999999862\n",
      "Error: 0.029756250000004782 Prediction: 0.6274999999999862\n",
      "Error: 0.029584000000004787 Prediction: 0.6279999999999861\n",
      "Error: 0.029412250000004792 Prediction: 0.6284999999999861\n",
      "Error: 0.029241000000004798 Prediction: 0.628999999999986\n",
      "Error: 0.029070250000004804 Prediction: 0.629499999999986\n",
      "Error: 0.028900000000004807 Prediction: 0.6299999999999859\n",
      "Error: 0.02873025000000481 Prediction: 0.6304999999999858\n",
      "Error: 0.028561000000004815 Prediction: 0.6309999999999858\n",
      "Error: 0.02839225000000482 Prediction: 0.6314999999999857\n",
      "Error: 0.028224000000004825 Prediction: 0.6319999999999857\n",
      "Error: 0.02805625000000483 Prediction: 0.6324999999999856\n",
      "Error: 0.027889000000004834 Prediction: 0.6329999999999856\n",
      "Error: 0.027722250000004837 Prediction: 0.6334999999999855\n",
      "Error: 0.02755600000000484 Prediction: 0.6339999999999855\n",
      "Error: 0.027390250000004845 Prediction: 0.6344999999999854\n",
      "Error: 0.02722500000000485 Prediction: 0.6349999999999854\n",
      "Error: 0.02706025000000485 Prediction: 0.6354999999999853\n",
      "Error: 0.026896000000004854 Prediction: 0.6359999999999852\n",
      "Error: 0.026732250000004856 Prediction: 0.6364999999999852\n",
      "Error: 0.02656900000000486 Prediction: 0.6369999999999851\n",
      "Error: 0.026406250000004863 Prediction: 0.6374999999999851\n",
      "Error: 0.026244000000004868 Prediction: 0.637999999999985\n",
      "Error: 0.02608225000000487 Prediction: 0.638499999999985\n",
      "Error: 0.02592100000000487 Prediction: 0.6389999999999849\n",
      "Error: 0.025760250000004873 Prediction: 0.6394999999999849\n",
      "Error: 0.025600000000004876 Prediction: 0.6399999999999848\n",
      "Error: 0.02544025000000488 Prediction: 0.6404999999999847\n",
      "Error: 0.025281000000004883 Prediction: 0.6409999999999847\n",
      "Error: 0.025122250000004884 Prediction: 0.6414999999999846\n",
      "Error: 0.024964000000004885 Prediction: 0.6419999999999846\n",
      "Error: 0.024806250000004887 Prediction: 0.6424999999999845\n",
      "Error: 0.02464900000000489 Prediction: 0.6429999999999845\n",
      "Error: 0.024492250000004892 Prediction: 0.6434999999999844\n",
      "Error: 0.024336000000004892 Prediction: 0.6439999999999844\n",
      "Error: 0.024180250000004896 Prediction: 0.6444999999999843\n",
      "Error: 0.024025000000004897 Prediction: 0.6449999999999843\n",
      "Error: 0.023870250000004898 Prediction: 0.6454999999999842\n",
      "Error: 0.023716000000004896 Prediction: 0.6459999999999841\n",
      "Error: 0.0235622500000049 Prediction: 0.6464999999999841\n",
      "Error: 0.023409000000004898 Prediction: 0.646999999999984\n",
      "Error: 0.0232562500000049 Prediction: 0.647499999999984\n",
      "Error: 0.023104000000004902 Prediction: 0.6479999999999839\n",
      "Error: 0.022952250000004903 Prediction: 0.6484999999999839\n",
      "Error: 0.0228010000000049 Prediction: 0.6489999999999838\n",
      "Error: 0.022650250000004903 Prediction: 0.6494999999999838\n",
      "Error: 0.0225000000000049 Prediction: 0.6499999999999837\n",
      "Error: 0.022350250000004904 Prediction: 0.6504999999999836\n",
      "Error: 0.022201000000004904 Prediction: 0.6509999999999836\n",
      "Error: 0.0220522500000049 Prediction: 0.6514999999999835\n",
      "Error: 0.021904000000004902 Prediction: 0.6519999999999835\n",
      "Error: 0.021756250000004904 Prediction: 0.6524999999999834\n",
      "Error: 0.021609000000004902 Prediction: 0.6529999999999834\n",
      "Error: 0.0214622500000049 Prediction: 0.6534999999999833\n",
      "Error: 0.0213160000000049 Prediction: 0.6539999999999833\n",
      "Error: 0.0211702500000049 Prediction: 0.6544999999999832\n",
      "Error: 0.021025000000004897 Prediction: 0.6549999999999832\n",
      "Error: 0.0208802500000049 Prediction: 0.6554999999999831\n",
      "Error: 0.020736000000004896 Prediction: 0.655999999999983\n",
      "Error: 0.020592250000004895 Prediction: 0.656499999999983\n",
      "Error: 0.020449000000004894 Prediction: 0.6569999999999829\n",
      "Error: 0.020306250000004893 Prediction: 0.6574999999999829\n",
      "Error: 0.02016400000000489 Prediction: 0.6579999999999828\n",
      "Error: 0.02002225000000489 Prediction: 0.6584999999999828\n",
      "Error: 0.019881000000004888 Prediction: 0.6589999999999827\n",
      "Error: 0.019740250000004886 Prediction: 0.6594999999999827\n",
      "Error: 0.019600000000004884 Prediction: 0.6599999999999826\n",
      "Error: 0.019460250000004883 Prediction: 0.6604999999999825\n",
      "Error: 0.01932100000000488 Prediction: 0.6609999999999825\n",
      "Error: 0.01918225000000488 Prediction: 0.6614999999999824\n",
      "Error: 0.019044000000004876 Prediction: 0.6619999999999824\n",
      "Error: 0.018906250000004874 Prediction: 0.6624999999999823\n",
      "Error: 0.01876900000000487 Prediction: 0.6629999999999823\n",
      "Error: 0.018632250000004867 Prediction: 0.6634999999999822\n",
      "Error: 0.018496000000004866 Prediction: 0.6639999999999822\n",
      "Error: 0.018360250000004862 Prediction: 0.6644999999999821\n",
      "Error: 0.01822500000000486 Prediction: 0.664999999999982\n",
      "Error: 0.018090250000004856 Prediction: 0.665499999999982\n",
      "Error: 0.017956000000004853 Prediction: 0.6659999999999819\n",
      "Error: 0.017822250000004848 Prediction: 0.6664999999999819\n",
      "Error: 0.017689000000004847 Prediction: 0.6669999999999818\n",
      "Error: 0.017556250000004842 Prediction: 0.6674999999999818\n",
      "Error: 0.01742400000000484 Prediction: 0.6679999999999817\n",
      "Error: 0.017292250000004835 Prediction: 0.6684999999999817\n",
      "Error: 0.01716100000000483 Prediction: 0.6689999999999816\n",
      "Error: 0.017030250000004826 Prediction: 0.6694999999999816\n",
      "Error: 0.01690000000000482 Prediction: 0.6699999999999815\n",
      "Error: 0.016770250000004816 Prediction: 0.6704999999999814\n",
      "Error: 0.01664100000000481 Prediction: 0.6709999999999814\n",
      "Error: 0.016512250000004808 Prediction: 0.6714999999999813\n",
      "Error: 0.016384000000004804 Prediction: 0.6719999999999813\n",
      "Error: 0.016256250000004798 Prediction: 0.6724999999999812\n",
      "Error: 0.016129000000004796 Prediction: 0.6729999999999812\n",
      "Error: 0.01600225000000479 Prediction: 0.6734999999999811\n",
      "Error: 0.015876000000004786 Prediction: 0.6739999999999811\n",
      "Error: 0.015750250000004778 Prediction: 0.674499999999981\n",
      "Error: 0.015625000000004774 Prediction: 0.674999999999981\n",
      "Error: 0.015500250000004769 Prediction: 0.6754999999999809\n",
      "Error: 0.015376000000004763 Prediction: 0.6759999999999808\n",
      "Error: 0.015252250000004757 Prediction: 0.6764999999999808\n",
      "Error: 0.015129000000004751 Prediction: 0.6769999999999807\n",
      "Error: 0.015006250000004747 Prediction: 0.6774999999999807\n",
      "Error: 0.01488400000000474 Prediction: 0.6779999999999806\n",
      "Error: 0.014762250000004733 Prediction: 0.6784999999999806\n",
      "Error: 0.014641000000004728 Prediction: 0.6789999999999805\n",
      "Error: 0.014520250000004722 Prediction: 0.6794999999999805\n",
      "Error: 0.014400000000004715 Prediction: 0.6799999999999804\n",
      "Error: 0.01428025000000471 Prediction: 0.6804999999999803\n",
      "Error: 0.014161000000004703 Prediction: 0.6809999999999803\n",
      "Error: 0.014042250000004695 Prediction: 0.6814999999999802\n",
      "Error: 0.013924000000004688 Prediction: 0.6819999999999802\n",
      "Error: 0.013806250000004681 Prediction: 0.6824999999999801\n",
      "Error: 0.013689000000004675 Prediction: 0.6829999999999801\n",
      "Error: 0.013572250000004667 Prediction: 0.68349999999998\n",
      "Error: 0.01345600000000466 Prediction: 0.68399999999998\n",
      "Error: 0.013340250000004652 Prediction: 0.6844999999999799\n",
      "Error: 0.013225000000004644 Prediction: 0.6849999999999798\n",
      "Error: 0.013110250000004637 Prediction: 0.6854999999999798\n",
      "Error: 0.01299600000000463 Prediction: 0.6859999999999797\n",
      "Error: 0.012882250000004623 Prediction: 0.6864999999999797\n",
      "Error: 0.012769000000004613 Prediction: 0.6869999999999796\n",
      "Error: 0.012656250000004607 Prediction: 0.6874999999999796\n",
      "Error: 0.012544000000004598 Prediction: 0.6879999999999795\n",
      "Error: 0.01243225000000459 Prediction: 0.6884999999999795\n",
      "Error: 0.012321000000004582 Prediction: 0.6889999999999794\n",
      "Error: 0.012210250000004573 Prediction: 0.6894999999999794\n",
      "Error: 0.012100000000004564 Prediction: 0.6899999999999793\n",
      "Error: 0.011990250000004556 Prediction: 0.6904999999999792\n",
      "Error: 0.011881000000004548 Prediction: 0.6909999999999792\n",
      "Error: 0.011772250000004538 Prediction: 0.6914999999999791\n",
      "Error: 0.011664000000004528 Prediction: 0.6919999999999791\n",
      "Error: 0.01155625000000452 Prediction: 0.692499999999979\n",
      "Error: 0.011449000000004511 Prediction: 0.692999999999979\n",
      "Error: 0.011342250000004502 Prediction: 0.6934999999999789\n",
      "Error: 0.011236000000004492 Prediction: 0.6939999999999789\n",
      "Error: 0.011130250000004482 Prediction: 0.6944999999999788\n",
      "Error: 0.011025000000004472 Prediction: 0.6949999999999787\n",
      "Error: 0.010920250000004463 Prediction: 0.6954999999999787\n",
      "Error: 0.010816000000004452 Prediction: 0.6959999999999786\n",
      "Error: 0.010712250000004442 Prediction: 0.6964999999999786\n",
      "Error: 0.010609000000004433 Prediction: 0.6969999999999785\n",
      "Error: 0.010506250000004422 Prediction: 0.6974999999999785\n",
      "Error: 0.010404000000004411 Prediction: 0.6979999999999784\n",
      "Error: 0.010302250000004402 Prediction: 0.6984999999999784\n",
      "Error: 0.01020100000000439 Prediction: 0.6989999999999783\n",
      "Error: 0.01010025000000438 Prediction: 0.6994999999999783\n",
      "Error: 0.01000000000000437 Prediction: 0.6999999999999782\n",
      "Error: 0.009900250000004359 Prediction: 0.7004999999999781\n",
      "Error: 0.009801000000004348 Prediction: 0.7009999999999781\n",
      "Error: 0.009702250000004338 Prediction: 0.701499999999978\n",
      "Error: 0.009604000000004326 Prediction: 0.701999999999978\n",
      "Error: 0.009506250000004315 Prediction: 0.7024999999999779\n",
      "Error: 0.009409000000004303 Prediction: 0.7029999999999779\n",
      "Error: 0.009312250000004291 Prediction: 0.7034999999999778\n",
      "Error: 0.00921600000000428 Prediction: 0.7039999999999778\n",
      "Error: 0.009120250000004267 Prediction: 0.7044999999999777\n",
      "Error: 0.009025000000004255 Prediction: 0.7049999999999776\n",
      "Error: 0.008930250000004244 Prediction: 0.7054999999999776\n",
      "Error: 0.008836000000004231 Prediction: 0.7059999999999775\n",
      "Error: 0.008742250000004219 Prediction: 0.7064999999999775\n",
      "Error: 0.008649000000004207 Prediction: 0.7069999999999774\n",
      "Error: 0.008556250000004194 Prediction: 0.7074999999999774\n",
      "Error: 0.008464000000004182 Prediction: 0.7079999999999773\n",
      "Error: 0.00837225000000417 Prediction: 0.7084999999999773\n",
      "Error: 0.008281000000004157 Prediction: 0.7089999999999772\n",
      "Error: 0.008190250000004144 Prediction: 0.7094999999999771\n",
      "Error: 0.008100000000004132 Prediction: 0.7099999999999771\n",
      "Error: 0.008010250000004118 Prediction: 0.710499999999977\n",
      "Error: 0.007921000000004105 Prediction: 0.710999999999977\n",
      "Error: 0.007832250000004091 Prediction: 0.7114999999999769\n",
      "Error: 0.007744000000004078 Prediction: 0.7119999999999769\n",
      "Error: 0.007656250000004064 Prediction: 0.7124999999999768\n",
      "Error: 0.007569000000004051 Prediction: 0.7129999999999768\n",
      "Error: 0.007482250000004037 Prediction: 0.7134999999999767\n",
      "Error: 0.0073960000000040235 Prediction: 0.7139999999999767\n",
      "Error: 0.00731025000000401 Prediction: 0.7144999999999766\n",
      "Error: 0.007225000000003996 Prediction: 0.7149999999999765\n",
      "Error: 0.007140250000003981 Prediction: 0.7154999999999765\n",
      "Error: 0.007056000000003967 Prediction: 0.7159999999999764\n",
      "Error: 0.006972250000003953 Prediction: 0.7164999999999764\n",
      "Error: 0.006889000000003938 Prediction: 0.7169999999999763\n",
      "Error: 0.006806250000003923 Prediction: 0.7174999999999763\n",
      "Error: 0.006724000000003908 Prediction: 0.7179999999999762\n",
      "Error: 0.006642250000003893 Prediction: 0.7184999999999762\n",
      "Error: 0.006561000000003879 Prediction: 0.7189999999999761\n",
      "Error: 0.006480250000003863 Prediction: 0.719499999999976\n",
      "Error: 0.006400000000003848 Prediction: 0.719999999999976\n",
      "Error: 0.006320250000003833 Prediction: 0.7204999999999759\n",
      "Error: 0.006241000000003817 Prediction: 0.7209999999999759\n",
      "Error: 0.006162250000003802 Prediction: 0.7214999999999758\n",
      "Error: 0.006084000000003786 Prediction: 0.7219999999999758\n",
      "Error: 0.006006250000003771 Prediction: 0.7224999999999757\n",
      "Error: 0.005929000000003755 Prediction: 0.7229999999999757\n",
      "Error: 0.005852250000003739 Prediction: 0.7234999999999756\n",
      "Error: 0.005776000000003723 Prediction: 0.7239999999999756\n",
      "Error: 0.005700250000003707 Prediction: 0.7244999999999755\n",
      "Error: 0.00562500000000369 Prediction: 0.7249999999999754\n",
      "Error: 0.005550250000003674 Prediction: 0.7254999999999754\n",
      "Error: 0.005476000000003658 Prediction: 0.7259999999999753\n",
      "Error: 0.005402250000003641 Prediction: 0.7264999999999753\n",
      "Error: 0.005329000000003624 Prediction: 0.7269999999999752\n",
      "Error: 0.005256250000003607 Prediction: 0.7274999999999752\n",
      "Error: 0.00518400000000359 Prediction: 0.7279999999999751\n",
      "Error: 0.005112250000003573 Prediction: 0.7284999999999751\n",
      "Error: 0.0050410000000035565 Prediction: 0.728999999999975\n",
      "Error: 0.004970250000003539 Prediction: 0.729499999999975\n",
      "Error: 0.004900000000003521 Prediction: 0.7299999999999749\n",
      "Error: 0.004830250000003504 Prediction: 0.7304999999999748\n",
      "Error: 0.004761000000003486 Prediction: 0.7309999999999748\n",
      "Error: 0.004692250000003469 Prediction: 0.7314999999999747\n",
      "Error: 0.004624000000003451 Prediction: 0.7319999999999747\n",
      "Error: 0.0045562500000034326 Prediction: 0.7324999999999746\n",
      "Error: 0.004489000000003415 Prediction: 0.7329999999999746\n",
      "Error: 0.0044222500000033966 Prediction: 0.7334999999999745\n",
      "Error: 0.004356000000003378 Prediction: 0.7339999999999745\n",
      "Error: 0.00429025000000336 Prediction: 0.7344999999999744\n",
      "Error: 0.0042250000000033415 Prediction: 0.7349999999999743\n",
      "Error: 0.004160250000003323 Prediction: 0.7354999999999743\n",
      "Error: 0.0040960000000033045 Prediction: 0.7359999999999742\n",
      "Error: 0.004032250000003285 Prediction: 0.7364999999999742\n",
      "Error: 0.003969000000003267 Prediction: 0.7369999999999741\n",
      "Error: 0.003906250000003247 Prediction: 0.7374999999999741\n",
      "Error: 0.003844000000003228 Prediction: 0.737999999999974\n",
      "Error: 0.003782250000003209 Prediction: 0.738499999999974\n",
      "Error: 0.0037210000000031896 Prediction: 0.7389999999999739\n",
      "Error: 0.00366025000000317 Prediction: 0.7394999999999738\n",
      "Error: 0.0036000000000031506 Prediction: 0.7399999999999738\n",
      "Error: 0.0035402500000031307 Prediction: 0.7404999999999737\n",
      "Error: 0.003481000000003111 Prediction: 0.7409999999999737\n",
      "Error: 0.0034222500000030912 Prediction: 0.7414999999999736\n",
      "Error: 0.003364000000003071 Prediction: 0.7419999999999736\n",
      "Error: 0.003306250000003051 Prediction: 0.7424999999999735\n",
      "Error: 0.0032490000000030307 Prediction: 0.7429999999999735\n",
      "Error: 0.0031922500000030104 Prediction: 0.7434999999999734\n",
      "Error: 0.0031360000000029897 Prediction: 0.7439999999999733\n",
      "Error: 0.003080250000002969 Prediction: 0.7444999999999733\n",
      "Error: 0.0030250000000029485 Prediction: 0.7449999999999732\n",
      "Error: 0.0029702500000029276 Prediction: 0.7454999999999732\n",
      "Error: 0.0029160000000029067 Prediction: 0.7459999999999731\n",
      "Error: 0.002862250000002886 Prediction: 0.7464999999999731\n",
      "Error: 0.0028090000000028648 Prediction: 0.746999999999973\n",
      "Error: 0.0027562500000028437 Prediction: 0.747499999999973\n",
      "Error: 0.002704000000002822 Prediction: 0.7479999999999729\n",
      "Error: 0.002652250000002801 Prediction: 0.7484999999999729\n",
      "Error: 0.002601000000002779 Prediction: 0.7489999999999728\n",
      "Error: 0.0025502500000027573 Prediction: 0.7494999999999727\n",
      "Error: 0.0025000000000027357 Prediction: 0.7499999999999727\n",
      "Error: 0.0024502500000027137 Prediction: 0.7504999999999726\n",
      "Error: 0.0024010000000026918 Prediction: 0.7509999999999726\n",
      "Error: 0.0023522500000026695 Prediction: 0.7514999999999725\n",
      "Error: 0.0023040000000026472 Prediction: 0.7519999999999725\n",
      "Error: 0.002256250000002625 Prediction: 0.7524999999999724\n",
      "Error: 0.0022090000000026025 Prediction: 0.7529999999999724\n",
      "Error: 0.00216225000000258 Prediction: 0.7534999999999723\n",
      "Error: 0.0021160000000025572 Prediction: 0.7539999999999722\n",
      "Error: 0.0020702500000025345 Prediction: 0.7544999999999722\n",
      "Error: 0.0020250000000025118 Prediction: 0.7549999999999721\n",
      "Error: 0.0019802500000024887 Prediction: 0.7554999999999721\n",
      "Error: 0.0019360000000024655 Prediction: 0.755999999999972\n",
      "Error: 0.0018922500000024423 Prediction: 0.756499999999972\n",
      "Error: 0.0018490000000024188 Prediction: 0.7569999999999719\n",
      "Error: 0.0018062500000023956 Prediction: 0.7574999999999719\n",
      "Error: 0.001764000000002372 Prediction: 0.7579999999999718\n",
      "Error: 0.0017222500000023482 Prediction: 0.7584999999999718\n",
      "Error: 0.0016810000000023245 Prediction: 0.7589999999999717\n",
      "Error: 0.0016402500000023007 Prediction: 0.7594999999999716\n",
      "Error: 0.0016000000000022767 Prediction: 0.7599999999999716\n",
      "Error: 0.0015602500000022525 Prediction: 0.7604999999999715\n",
      "Error: 0.0015210000000022283 Prediction: 0.7609999999999715\n",
      "Error: 0.001482250000002204 Prediction: 0.7614999999999714\n",
      "Error: 0.0014440000000021794 Prediction: 0.7619999999999714\n",
      "Error: 0.001406250000002155 Prediction: 0.7624999999999713\n",
      "Error: 0.0013690000000021302 Prediction: 0.7629999999999713\n",
      "Error: 0.0013322500000021056 Prediction: 0.7634999999999712\n",
      "Error: 0.0012960000000020806 Prediction: 0.7639999999999711\n",
      "Error: 0.0012602500000020557 Prediction: 0.7644999999999711\n",
      "Error: 0.0012250000000020305 Prediction: 0.764999999999971\n",
      "Error: 0.0011902500000020052 Prediction: 0.765499999999971\n",
      "Error: 0.00115600000000198 Prediction: 0.7659999999999709\n",
      "Error: 0.0011222500000019546 Prediction: 0.7664999999999709\n",
      "Error: 0.0010890000000019291 Prediction: 0.7669999999999708\n",
      "Error: 0.0010562500000019033 Prediction: 0.7674999999999708\n",
      "Error: 0.0010240000000018776 Prediction: 0.7679999999999707\n",
      "Error: 0.0009922500000018517 Prediction: 0.7684999999999707\n",
      "Error: 0.0009610000000018258 Prediction: 0.7689999999999706\n",
      "Error: 0.0009302500000017998 Prediction: 0.7694999999999705\n",
      "Error: 0.0009000000000017735 Prediction: 0.7699999999999705\n",
      "Error: 0.0008702500000017472 Prediction: 0.7704999999999704\n",
      "Error: 0.0008410000000017208 Prediction: 0.7709999999999704\n",
      "Error: 0.0008122500000016942 Prediction: 0.7714999999999703\n",
      "Error: 0.0007840000000016676 Prediction: 0.7719999999999703\n",
      "Error: 0.0007562500000016409 Prediction: 0.7724999999999702\n",
      "Error: 0.000729000000001614 Prediction: 0.7729999999999702\n",
      "Error: 0.000702250000001587 Prediction: 0.7734999999999701\n",
      "Error: 0.0006760000000015599 Prediction: 0.77399999999997\n",
      "Error: 0.0006502500000015327 Prediction: 0.77449999999997\n",
      "Error: 0.0006250000000015054 Prediction: 0.7749999999999699\n",
      "Error: 0.0006002500000014781 Prediction: 0.7754999999999699\n",
      "Error: 0.0005760000000014506 Prediction: 0.7759999999999698\n",
      "Error: 0.0005522500000014229 Prediction: 0.7764999999999698\n",
      "Error: 0.0005290000000013951 Prediction: 0.7769999999999697\n",
      "Error: 0.0005062500000013673 Prediction: 0.7774999999999697\n",
      "Error: 0.00048400000000133937 Prediction: 0.7779999999999696\n",
      "Error: 0.0004622500000013113 Prediction: 0.7784999999999695\n",
      "Error: 0.0004410000000012831 Prediction: 0.7789999999999695\n",
      "Error: 0.0004202500000012548 Prediction: 0.7794999999999694\n",
      "Error: 0.0004000000000012264 Prediction: 0.7799999999999694\n",
      "Error: 0.0003802500000011979 Prediction: 0.7804999999999693\n",
      "Error: 0.00036100000000116925 Prediction: 0.7809999999999693\n",
      "Error: 0.0003422500000011405 Prediction: 0.7814999999999692\n",
      "Error: 0.0003240000000011117 Prediction: 0.7819999999999692\n",
      "Error: 0.00030625000000108273 Prediction: 0.7824999999999691\n",
      "Error: 0.00028900000000105366 Prediction: 0.782999999999969\n",
      "Error: 0.0002722500000010245 Prediction: 0.783499999999969\n",
      "Error: 0.00025600000000099523 Prediction: 0.7839999999999689\n",
      "Error: 0.00024025000000096582 Prediction: 0.7844999999999689\n",
      "Error: 0.0002250000000009363 Prediction: 0.7849999999999688\n",
      "Error: 0.0002102500000009067 Prediction: 0.7854999999999688\n",
      "Error: 0.00019600000000087698 Prediction: 0.7859999999999687\n",
      "Error: 0.00018225000000084715 Prediction: 0.7864999999999687\n",
      "Error: 0.0001690000000008172 Prediction: 0.7869999999999686\n",
      "Error: 0.00015625000000078716 Prediction: 0.7874999999999686\n",
      "Error: 0.000144000000000757 Prediction: 0.7879999999999685\n",
      "Error: 0.0001322500000007267 Prediction: 0.7884999999999684\n",
      "Error: 0.00012100000000069633 Prediction: 0.7889999999999684\n",
      "Error: 0.00011025000000066583 Prediction: 0.7894999999999683\n",
      "Error: 0.00010000000000063523 Prediction: 0.7899999999999683\n",
      "Error: 9.025000000060451e-05 Prediction: 0.7904999999999682\n",
      "Error: 8.100000000057368e-05 Prediction: 0.7909999999999682\n",
      "Error: 7.225000000054275e-05 Prediction: 0.7914999999999681\n",
      "Error: 6.40000000005117e-05 Prediction: 0.7919999999999681\n",
      "Error: 5.625000000048055e-05 Prediction: 0.792499999999968\n",
      "Error: 4.9000000000449285e-05 Prediction: 0.792999999999968\n",
      "Error: 4.225000000041791e-05 Prediction: 0.7934999999999679\n",
      "Error: 3.6000000000386424e-05 Prediction: 0.7939999999999678\n",
      "Error: 3.0250000000354826e-05 Prediction: 0.7944999999999678\n",
      "Error: 2.500000000032312e-05 Prediction: 0.7949999999999677\n",
      "Error: 2.0250000000291302e-05 Prediction: 0.7954999999999677\n",
      "Error: 1.6000000000259378e-05 Prediction: 0.7959999999999676\n",
      "Error: 1.225000000022734e-05 Prediction: 0.7964999999999676\n",
      "Error: 9.000000000195194e-06 Prediction: 0.7969999999999675\n",
      "Error: 6.250000000162936e-06 Prediction: 0.7974999999999675\n",
      "Error: 4.000000000130569e-06 Prediction: 0.7979999999999674\n",
      "Error: 2.2500000000980924e-06 Prediction: 0.7984999999999673\n",
      "Error: 1.000000000065505e-06 Prediction: 0.7989999999999673\n",
      "Error: 2.5000000003280753e-07 Prediction: 0.7994999999999672\n",
      "Error: 1.0799505792475652e-27 Prediction: 0.7999999999999672\n"
     ]
    }
   ],
   "source": [
    "# Page 77\n",
    "weight = 0.5\n",
    "inp = 0.5\n",
    "goal_prediction = 0.8\n",
    "\n",
    "step_amount = 0.001\n",
    "\n",
    "for i in range(1101):\n",
    "    prediction = inp * weight\n",
    "    error = (prediction - goal_prediction) ** 2\n",
    "    \n",
    "    print(\"Error: \" + str(error) + \" Prediction: \" + str(prediction))\n",
    "    \n",
    "    up_prediction = inp * (weight + step_amount)\n",
    "    up_error = (goal_prediction - up_prediction) ** 2\n",
    "    \n",
    "    down_prediction = inp * (weight - step_amount)\n",
    "    down_error = (goal_prediction - down_prediction) ** 2\n",
    "    \n",
    "    if down_error < up_error:\n",
    "        weight -= step_amount\n",
    "    elif up_error < down_error:\n",
    "        weight += step_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Weight:0.0\n",
      "Error:0.6400000000000001 Prediction:0.0\n",
      "Delta:-0.8 Weight Delta:-0.8800000000000001\n",
      "---------\n",
      "Weight:0.8800000000000001\n",
      "Error:0.02822400000000005 Prediction:0.9680000000000002\n",
      "Delta:0.16800000000000015 Weight Delta:0.1848000000000002\n",
      "---------\n",
      "Weight:0.6951999999999999\n",
      "Error:0.0012446784000000064 Prediction:0.76472\n",
      "Delta:-0.03528000000000009 Weight Delta:-0.0388080000000001\n",
      "---------\n",
      "Weight:0.734008\n",
      "Error:5.4890317439999896e-05 Prediction:0.8074088\n",
      "Delta:0.007408799999999993 Weight Delta:0.008149679999999992\n"
     ]
    }
   ],
   "source": [
    "# Page 86\n",
    "weight, goal_pred, inp = (0.0, 0.8, 1.1)\n",
    "    \n",
    "for iteration in range(4):\n",
    "    print(\"---------\\nWeight:\" + str(weight))\n",
    "    \n",
    "    pred = inp * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    delta = pred - goal_pred\n",
    "    weight_delta = delta * inp\n",
    "    weight -= weight_delta\n",
    "    \n",
    "    print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))\n",
    "    print(\"Delta:\" + str(delta) + \" Weight Delta:\" + str(weight_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2420.6400000000003Prediction: 50.0\n",
      "Error: 24.20639999999992Prediction: 5.719999999999992\n",
      "Error: 0.24206399999999867Prediction: 1.2919999999999987\n",
      "Error: 0.0024206399999999913Prediction: 0.8492\n",
      "Error: 2.4206399999999257e-05Prediction: 0.80492\n",
      "Error: 2.420640000000472e-07Prediction: 0.8004920000000001\n",
      "Error: 2.4206399999971946e-09Prediction: 0.8000492\n",
      "Error: 2.4206399999644208e-11Prediction: 0.80000492\n",
      "Error: 2.420639999636683e-13Prediction: 0.800000492\n",
      "Number of iterations: 9\n"
     ]
    }
   ],
   "source": [
    "# My own gradient-boosting after Chapter 4\n",
    "inp = 100\n",
    "weight = 0.5\n",
    "goal_pred = 0.8\n",
    "\n",
    "error = 1\n",
    "alpha = 0.00009\n",
    "\n",
    "count_of_iterations = 0\n",
    "\n",
    "while error > 10 ** -12:\n",
    "    count_of_iterations += 1\n",
    "    \n",
    "    pred = inp * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    \n",
    "    boost = alpha * inp * (pred - goal_pred)\n",
    "    weight -= boost\n",
    "    \n",
    "    print(\"Error: \" + str(error) + \"Prediction: \" + str(pred))\n",
    "    \n",
    "print(\"Number of iterations: \" + str(count_of_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Github\n"
     ]
    }
   ],
   "source": [
    "#New practice\n",
    "hey_you = 'Hello Github'\n",
    "print(hey_you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2.6561231104\n",
      "Error: 0.9628701776715985\n",
      "Error: 0.5509165866836797\n",
      "Error: 0.36445836852222424\n",
      "Error: 0.2516768662079895\n",
      "Error: 0.17797575048089034\n",
      "Error: 0.12864460733422164\n",
      "Error: 0.09511036950476208\n",
      "Error: 0.07194564247043436\n",
      "Error: 0.05564914990717743\n",
      "Error: 0.04394763937673939\n",
      "Error: 0.035357967050948465\n",
      "Error: 0.02890700056547436\n",
      "Error: 0.023951660591138853\n",
      "Error: 0.020063105176016144\n",
      "Error: 0.016952094519447087\n",
      "Error: 0.014420818295271236\n",
      "Error: 0.012331739998443648\n",
      "Error: 0.010587393171639842\n",
      "Error: 0.009117233405426495\n",
      "Error: 0.00786904226904208\n",
      "Error: 0.006803273214640502\n",
      "Error: 0.005889303541837786\n",
      "Error: 0.0051029252561172675\n",
      "Error: 0.004424644608684828\n",
      "Error: 0.0038385124412518303\n",
      "Error: 0.0033313054558089675\n",
      "Error: 0.0028919416227737734\n",
      "Error: 0.002511053608117256\n",
      "Error: 0.0021806703520253884\n",
      "Error: 0.0018939739123713475\n",
      "Error: 0.0016451096996342332\n",
      "Error: 0.0014290353984827077\n",
      "Error: 0.0012413985592149145\n",
      "Error: 0.0010784359268087556\n",
      "Error: 0.0009368896209360312\n",
      "Error: 0.0008139366504753339\n",
      "Error: 0.0007071291752624441\n",
      "Error: 0.0006143435674831474\n",
      "Error: 0.00053373677328488\n"
     ]
    }
   ],
   "source": [
    "# Page 138\n",
    "import numpy as np\n",
    "\n",
    "weights = np.array([0.5, 0.48, -0.7])\n",
    "alpha = 0.1\n",
    "\n",
    "streetlights = np.array( [[1, 0, 1],\n",
    "                          [0, 1, 1],\n",
    "                          [0, 0, 1],\n",
    "                          [1, 1, 1],\n",
    "                          [0, 1, 1], \n",
    "                          [1, 0, 1]] )\n",
    "\n",
    "walk_vs_stop = np.array([0, 1, 0, 1, 1, 0])\n",
    "\n",
    "inp = streetlights[0]\n",
    "goal_pred = walk_vs_stop[0]\n",
    "\n",
    "for i in range(40):\n",
    "    error_for_all_lights = 0\n",
    "    \n",
    "    for row_index in range(len(walk_vs_stop)):\n",
    "        inp = streetlights[row_index]\n",
    "        goal_pred = walk_vs_stop[row_index]\n",
    "        \n",
    "        pred = inp.dot(weights)\n",
    "        \n",
    "        error = (goal_pred - pred) ** 2\n",
    "        error_for_all_lights += error\n",
    "        \n",
    "        delta = pred - goal_pred\n",
    "        weights -= alpha * (inp * delta)\n",
    "        # print('Prediction: {}'.format(pred))\n",
    "        \n",
    "    print('Error: {}'.format(error_for_all_lights))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.31298811341557736\n",
      "Error:0.043272385299784624\n",
      "Error:0.0034372657015086937\n",
      "Error:0.00019649599346773566\n",
      "Error:1.015593230102771e-05\n",
      "Error:5.122102420300414e-07\n"
     ]
    }
   ],
   "source": [
    "# Page 157 (162)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output > 0\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array( [[1, 0, 1],\n",
    "                          [0, 1, 1],\n",
    "                          [0, 0, 1],\n",
    "                          [1, 1, 1],\n",
    "                          [0, 1, 1], \n",
    "                          [1, 0, 1]] )\n",
    "\n",
    "walk_vs_stop = np.array([0, 1, 0, 1, 1, 0])\n",
    "\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "# print(weights_0_1)\n",
    "\n",
    "for iteration in range(60):\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        layer_0 = streetlights[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
    "        \n",
    "        layer_2_delta = layer_2 - walk_vs_stop[i:i+1]\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    if (iteration % 10 == 9): #      \n",
    "        print (\"Error:\" + str(layer_2_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True  True]]\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "# Test\n",
    "lights = np.array( [[1, 0, 1],\n",
    "                    [0, 1, 1],\n",
    "                    [0, 0, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [0, 1, 1], \n",
    "                    [1, 0, 1]] )\n",
    "\n",
    "print(lights[4:5] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.718 Test-Acc:0.5418 Train-Err:0.885 Train-Err:0.289\n",
      "I:10 Test-Err:0.501 Test-Acc:0.7365 Train-Err:0.564 Train-Err:0.647\n",
      "I:20 Test-Err:0.478 Test-Acc:0.7621 Train-Err:0.530 Train-Err:0.681\n",
      "I:30 Test-Err:0.457 Test-Acc:0.7915 Train-Err:0.508 Train-Err:0.71\n",
      "I:40 Test-Err:0.445 Test-Acc:0.7998 Train-Err:0.492 Train-Err:0.719\n",
      "I:50 Test-Err:0.430 Test-Acc:0.8145 Train-Err:0.462 Train-Err:0.742\n",
      "I:60 Test-Err:0.446 Test-Acc:0.7974 Train-Err:0.472 Train-Err:0.746\n",
      "I:70 Test-Err:0.445 Test-Acc:0.7901 Train-Err:0.463 Train-Err:0.744\n",
      "I:80 Test-Err:0.426 Test-Acc:0.8105 Train-Err:0.461 Train-Err:0.764\n",
      "I:90 Test-Err:0.435 Test-Acc:0.7871 Train-Err:0.462 Train-Err:0.749\n",
      "I:100 Test-Err:0.433 Test-Acc:0.8039 Train-Err:0.452 Train-Err:0.769\n",
      "I:110 Test-Err:0.435 Test-Acc:0.8099 Train-Err:0.439 Train-Err:0.778\n",
      "I:120 Test-Err:0.442 Test-Acc:0.7871 Train-Err:0.451 Train-Err:0.778\n",
      "I:130 Test-Err:0.439 Test-Acc:0.811 Train-Err:0.452 Train-Err:0.783\n",
      "I:140 Test-Err:0.443 Test-Acc:0.8049 Train-Err:0.445 Train-Err:0.779\n",
      "I:150 Test-Err:0.446 Test-Acc:0.7918 Train-Err:0.457 Train-Err:0.783\n",
      "I:160 Test-Err:0.437 Test-Acc:0.81 Train-Err:0.456 Train-Err:0.774\n",
      "I:170 Test-Err:0.430 Test-Acc:0.7963 Train-Err:0.439 Train-Err:0.801\n",
      "I:180 Test-Err:0.432 Test-Acc:0.7955 Train-Err:0.453 Train-Err:0.782\n",
      "I:190 Test-Err:0.436 Test-Acc:0.7997 Train-Err:0.433 Train-Err:0.784\n",
      "I:200 Test-Err:0.436 Test-Acc:0.803 Train-Err:0.442 Train-Err:0.796\n",
      "I:210 Test-Err:0.434 Test-Acc:0.8031 Train-Err:0.441 Train-Err:0.79\n",
      "I:220 Test-Err:0.426 Test-Acc:0.8102 Train-Err:0.434 Train-Err:0.777\n",
      "I:230 Test-Err:0.429 Test-Acc:0.8058 Train-Err:0.431 Train-Err:0.803\n",
      "I:240 Test-Err:0.436 Test-Acc:0.8055 Train-Err:0.430 Train-Err:0.788\n",
      "I:250 Test-Err:0.421 Test-Acc:0.8053 Train-Err:0.433 Train-Err:0.789\n",
      "I:260 Test-Err:0.422 Test-Acc:0.8102 Train-Err:0.422 Train-Err:0.79\n",
      "I:270 Test-Err:0.438 Test-Acc:0.8062 Train-Err:0.430 Train-Err:0.803\n",
      "I:280 Test-Err:0.431 Test-Acc:0.7991 Train-Err:0.425 Train-Err:0.79\n",
      "I:290 Test-Err:0.433 Test-Acc:0.8028 Train-Err:0.428 Train-Err:0.792\n",
      "I:300 Test-Err:0.434 Test-Acc:0.7949 Train-Err:0.407 Train-Err:0.804\n",
      "I:310 Test-Err:0.428 Test-Acc:0.8036 Train-Err:0.415 Train-Err:0.793\n",
      "I:320 Test-Err:0.436 Test-Acc:0.8008 Train-Err:0.415 Train-Err:0.812\n",
      "I:330 Test-Err:0.419 Test-Acc:0.8134 Train-Err:0.418 Train-Err:0.817\n",
      "I:340 Test-Err:0.431 Test-Acc:0.8012 Train-Err:0.408 Train-Err:0.814"
     ]
    }
   ],
   "source": [
    "# Page 180 - 190\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "np.random.seed(1)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000, 28*28) /\\\n",
    "                                     255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(labels), 10))\n",
    "\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test), 28*28) / 255\n",
    "test_labels = np.zeros((len(y_test), 10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "    \n",
    "relu = lambda x: (x >= 0) * x\n",
    "relu2deriv = lambda output: output >= 0\n",
    "\n",
    "alpha, iterations, hidden_size = (0.005, 350, 40)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "\n",
    "weights_0_1 = 0.2 * np.random.random((pixels_per_image, hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "\n",
    "        #   ()\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        #   \n",
    "        layer_1 *= dropout_mask * 2\n",
    "        \n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                              np.argmax(labels[i:i+1]))\n",
    "        \n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\\\n",
    "                                        * relu2deriv(layer_1)\n",
    "        #    Back-Propagation\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "    \n",
    "    if (j % 10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "        \n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "            \n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                   np.argmax(test_labels[i:i+1]))\n",
    "        \n",
    "        sys.stdout.write('\\n' + \\\n",
    "            'I:' + str(j) + \\\n",
    "            ' Test-Err:' + str(test_error/float(len(test_images)))[0:5] +\\\n",
    "            ' Test-Acc:' + str(test_correct_cnt/float(len(test_images))) +\\\n",
    "            ' Train-Err:' + str(error/float(len(images)))[0:5] +\\\n",
    "            ' Train-Err:' + str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Activation Functions such as tanh, softmax and their backprop versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 212-214 - We are investigating new activation functions\n",
    "\n",
    "import numpy as np, sys\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)\\\n",
    "                                                 / 255, y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Page 212-214 - We are investigating new activation functions\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels), 10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test), 28*28) / 255\n",
    "test_labels = np.zeros((len(y_test), 10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Page 212-214 - We are investigating new activation functions\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh2deriv(output):\n",
    "    return 1 - (output ** 2)\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "    \n",
    "alpha, iterations, hidden_size = (2, 300, 100)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.02 * np.random.random((pixels_per_image, hidden_size)) - 0.01\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Acc:0.394 Train-Acc:0.156\n",
      "I:10 Test-Acc:0.6867 Train-Acc:0.723\n",
      "I:20 Test-Acc:0.7025 Train-Acc:0.732\n",
      "I:30 Test-Acc:0.734 Train-Acc:0.763\n",
      "I:40 Test-Acc:0.7663 Train-Acc:0.794\n",
      "I:50 Test-Acc:0.7913 Train-Acc:0.819\n",
      "I:60 Test-Acc:0.8102 Train-Acc:0.849\n",
      "I:70 Test-Acc:0.8228 Train-Acc:0.864\n",
      "I:80 Test-Acc:0.831 Train-Acc:0.867\n",
      "I:90 Test-Acc:0.8364 Train-Acc:0.885\n",
      "I:100 Test-Acc:0.8407 Train-Acc:0.883\n",
      "I:110 Test-Acc:0.845 Train-Acc:0.891\n",
      "I:120 Test-Acc:0.8481 Train-Acc:0.901\n",
      "I:130 Test-Acc:0.8505 Train-Acc:0.901\n",
      "I:140 Test-Acc:0.8526 Train-Acc:0.905\n",
      "I:150 Test-Acc:0.8555 Train-Acc:0.914\n",
      "I:160 Test-Acc:0.8577 Train-Acc:0.925\n",
      "I:170 Test-Acc:0.8596 Train-Acc:0.918\n",
      "I:180 Test-Acc:0.8619 Train-Acc:0.933\n",
      "I:190 Test-Acc:0.863 Train-Acc:0.933\n",
      "I:200 Test-Acc:0.8642 Train-Acc:0.926\n",
      "I:210 Test-Acc:0.8653 Train-Acc:0.931\n",
      "I:220 Test-Acc:0.8668 Train-Acc:0.93\n",
      "I:230 Test-Acc:0.8672 Train-Acc:0.937\n",
      "I:240 Test-Acc:0.8681 Train-Acc:0.938\n",
      "I:250 Test-Acc:0.8687 Train-Acc:0.937\n",
      "I:260 Test-Acc:0.8684 Train-Acc:0.945\n",
      "I:270 Test-Acc:0.8703 Train-Acc:0.951\n",
      "I:280 Test-Acc:0.8699 Train-Acc:0.949\n",
      "I:290 Test-Acc:0.8701 Train-Acc:0.94"
     ]
    }
   ],
   "source": [
    "#4 Page 212-214 - We are investigating new activation functions\n",
    "\n",
    "for j in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_start, batch_end = ((i * batch_size), ((i+1) * batch_size))\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_1 = tanh(np.dot(layer_0, weights_0_1))\n",
    "        \n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == \\\n",
    "                              np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
    "        \n",
    "        layer_2_delta = (labels[batch_start:batch_end]-layer_2) \\\n",
    "                        / (batch_size * layer_2.shape[0])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) \\\n",
    "                        * tanh2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "    \n",
    "    test_correct_cnt = 0\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = tanh(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        test_correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                              np.argmax(test_labels[i:i+1]))\n",
    "        \n",
    "    if (j % 10 == 0):\n",
    "        sys.stdout.write(\"\\n\"+ \"I:\" + str(j) + \\\n",
    "        \" Test-Acc:\"+str(test_correct_cnt/float(len(test_images)))+\\\n",
    "        \" Train-Acc:\" + str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 221-223 - We are investigating convolutional neural networks\n",
    "\n",
    "import numpy as np, sys\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Page 221-223 - We are investigating convolutional neural networks\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000, 28*28) / 255,\n",
    "                  y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels), 10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test), 28*28) / 255\n",
    "test_labels = np.zeros((len(y_test), 10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Page 221-223 - We are investigating convolutional neural networks\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh2deriv(output):\n",
    "    return 1 - (output ** 2)\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "alpha, iterations = (2, 300)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 128\n",
    "\n",
    "input_rows = 28\n",
    "input_cols = 28\n",
    "\n",
    "kernel_rows = 3\n",
    "kernel_cols = 3\n",
    "num_kernels = 16\n",
    "\n",
    "hidden_size = ((input_rows - kernel_rows) *\n",
    "              (input_cols - kernel_cols)) * num_kernels\n",
    "\n",
    "kernels = 0.02 * np.random.random((kernel_rows * kernel_cols,\n",
    "                                 num_kernels)) - 0.01\n",
    "\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size,\n",
    "                                     num_labels)) - 0.1\n",
    "\n",
    "def get_image_section(layer, row_from, row_to, col_from, col_to):\n",
    "    section = layer[:, row_from:row_to, col_from:col_to]\n",
    "    return section.reshape(-1, 1, row_to-row_from, col_to-col_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Acc:0.4023 Train-Acc:0.209\n",
      "I:1 Test-Acc:0.4358 Train-Acc:0.238\n",
      "I:2 Test-Acc:0.4473 Train-Acc:0.286\n",
      "I:3 Test-Acc:0.4389 Train-Acc:0.274\n",
      "I:4 Test-Acc:0.3951 Train-Acc:0.257\n",
      "I:5 Test-Acc:0.2222 Train-Acc:0.243\n",
      "I:6 Test-Acc:0.0613 Train-Acc:0.112\n",
      "I:7 Test-Acc:0.0266 Train-Acc:0.035\n",
      "I:8 Test-Acc:0.0127 Train-Acc:0.026\n",
      "I:9 Test-Acc:0.0133 Train-Acc:0.022\n",
      "I:10 Test-Acc:0.0185 Train-Acc:0.038\n",
      "I:11 Test-Acc:0.0363 Train-Acc:0.038\n",
      "I:12 Test-Acc:0.0928 Train-Acc:0.067\n",
      "I:13 Test-Acc:0.1994 Train-Acc:0.081\n",
      "I:14 Test-Acc:0.3086 Train-Acc:0.154\n",
      "I:15 Test-Acc:0.4276 Train-Acc:0.204\n",
      "I:16 Test-Acc:0.5323 Train-Acc:0.256\n",
      "I:17 Test-Acc:0.5919 Train-Acc:0.305\n",
      "I:18 Test-Acc:0.6324 Train-Acc:0.341\n",
      "I:19 Test-Acc:0.6608 Train-Acc:0.426\n",
      "I:20 Test-Acc:0.6815 Train-Acc:0.439\n",
      "I:21 Test-Acc:0.7048 Train-Acc:0.462\n",
      "I:22 Test-Acc:0.7171 Train-Acc:0.484\n",
      "I:23 Test-Acc:0.7313 Train-Acc:0.505\n",
      "I:24 Test-Acc:0.7355 Train-Acc:0.53\n",
      "I:25 Test-Acc:0.7417 Train-Acc:0.548\n",
      "I:26 Test-Acc:0.747 Train-Acc:0.534\n",
      "I:27 Test-Acc:0.7491 Train-Acc:0.55\n",
      "I:28 Test-Acc:0.7459 Train-Acc:0.562\n",
      "I:29 Test-Acc:0.7352 Train-Acc:0.54\n",
      "I:30 Test-Acc:0.7082 Train-Acc:0.496\n",
      "I:31 Test-Acc:0.6487 Train-Acc:0.456\n",
      "I:32 Test-Acc:0.5209 Train-Acc:0.353\n",
      "I:33 Test-Acc:0.3305 Train-Acc:0.234\n",
      "I:34 Test-Acc:0.2052 Train-Acc:0.174\n",
      "I:35 Test-Acc:0.2149 Train-Acc:0.136\n",
      "I:36 Test-Acc:0.2679 Train-Acc:0.171\n",
      "I:37 Test-Acc:0.3237 Train-Acc:0.172\n",
      "I:38 Test-Acc:0.3581 Train-Acc:0.186\n",
      "I:39 Test-Acc:0.4202 Train-Acc:0.21\n",
      "I:40 Test-Acc:0.5165 Train-Acc:0.223\n",
      "I:41 Test-Acc:0.6007 Train-Acc:0.262\n",
      "I:42 Test-Acc:0.6476 Train-Acc:0.308\n",
      "I:43 Test-Acc:0.676 Train-Acc:0.363\n",
      "I:44 Test-Acc:0.696 Train-Acc:0.402\n",
      "I:45 Test-Acc:0.7077 Train-Acc:0.434\n",
      "I:46 Test-Acc:0.7204 Train-Acc:0.441\n",
      "I:47 Test-Acc:0.7303 Train-Acc:0.475\n",
      "I:48 Test-Acc:0.7359 Train-Acc:0.475\n",
      "I:49 Test-Acc:0.7401 Train-Acc:0.525\n",
      "I:50 Test-Acc:0.7493 Train-Acc:0.517\n",
      "I:51 Test-Acc:0.7533 Train-Acc:0.517\n",
      "I:52 Test-Acc:0.7606 Train-Acc:0.538\n",
      "I:53 Test-Acc:0.7644 Train-Acc:0.554\n",
      "I:54 Test-Acc:0.7724 Train-Acc:0.57\n",
      "I:55 Test-Acc:0.7788 Train-Acc:0.586\n",
      "I:56 Test-Acc:0.7855 Train-Acc:0.595\n",
      "I:57 Test-Acc:0.7853 Train-Acc:0.591\n",
      "I:58 Test-Acc:0.7925 Train-Acc:0.605\n",
      "I:59 Test-Acc:0.7973 Train-Acc:0.64\n",
      "I:60 Test-Acc:0.8013 Train-Acc:0.621\n",
      "I:61 Test-Acc:0.8029 Train-Acc:0.626\n",
      "I:62 Test-Acc:0.8092 Train-Acc:0.631\n",
      "I:63 Test-Acc:0.8099 Train-Acc:0.638\n",
      "I:64 Test-Acc:0.8156 Train-Acc:0.661\n",
      "I:65 Test-Acc:0.8156 Train-Acc:0.639\n",
      "I:66 Test-Acc:0.8184 Train-Acc:0.65\n",
      "I:67 Test-Acc:0.8216 Train-Acc:0.67\n",
      "I:68 Test-Acc:0.8246 Train-Acc:0.675\n",
      "I:69 Test-Acc:0.8237 Train-Acc:0.666\n",
      "I:70 Test-Acc:0.8273 Train-Acc:0.673\n",
      "I:71 Test-Acc:0.8273 Train-Acc:0.704\n",
      "I:72 Test-Acc:0.8314 Train-Acc:0.674\n",
      "I:73 Test-Acc:0.8292 Train-Acc:0.686\n",
      "I:74 Test-Acc:0.8335 Train-Acc:0.699\n",
      "I:75 Test-Acc:0.8359 Train-Acc:0.694\n",
      "I:76 Test-Acc:0.8375 Train-Acc:0.704\n",
      "I:77 Test-Acc:0.8373 Train-Acc:0.697\n",
      "I:78 Test-Acc:0.8398 Train-Acc:0.704\n",
      "I:79 Test-Acc:0.8393 Train-Acc:0.687\n",
      "I:80 Test-Acc:0.8436 Train-Acc:0.705\n",
      "I:81 Test-Acc:0.8437 Train-Acc:0.711\n",
      "I:82 Test-Acc:0.8446 Train-Acc:0.721\n",
      "I:83 Test-Acc:0.845 Train-Acc:0.719\n",
      "I:84 Test-Acc:0.8469 Train-Acc:0.724\n",
      "I:85 Test-Acc:0.8476 Train-Acc:0.726\n",
      "I:86 Test-Acc:0.848 Train-Acc:0.718\n",
      "I:87 Test-Acc:0.8496 Train-Acc:0.719\n",
      "I:88 Test-Acc:0.85 Train-Acc:0.73\n",
      "I:89 Test-Acc:0.8511 Train-Acc:0.737\n",
      "I:90 Test-Acc:0.8503 Train-Acc:0.73\n",
      "I:91 Test-Acc:0.8504 Train-Acc:0.717\n",
      "I:92 Test-Acc:0.8528 Train-Acc:0.74\n",
      "I:93 Test-Acc:0.8532 Train-Acc:0.733\n",
      "I:94 Test-Acc:0.8537 Train-Acc:0.73\n",
      "I:95 Test-Acc:0.8568 Train-Acc:0.721\n",
      "I:96 Test-Acc:0.857 Train-Acc:0.75\n",
      "I:97 Test-Acc:0.8558 Train-Acc:0.731\n",
      "I:98 Test-Acc:0.8578 Train-Acc:0.744\n",
      "I:99 Test-Acc:0.8588 Train-Acc:0.754\n",
      "I:100 Test-Acc:0.8579 Train-Acc:0.732\n",
      "I:101 Test-Acc:0.8582 Train-Acc:0.747\n",
      "I:102 Test-Acc:0.8593 Train-Acc:0.747\n",
      "I:103 Test-Acc:0.8598 Train-Acc:0.751\n",
      "I:104 Test-Acc:0.8603 Train-Acc:0.74\n",
      "I:105 Test-Acc:0.86 Train-Acc:0.753\n",
      "I:106 Test-Acc:0.8588 Train-Acc:0.746\n",
      "I:107 Test-Acc:0.861 Train-Acc:0.741\n",
      "I:108 Test-Acc:0.8616 Train-Acc:0.731\n",
      "I:109 Test-Acc:0.8629 Train-Acc:0.753\n",
      "I:110 Test-Acc:0.8609 Train-Acc:0.743\n",
      "I:111 Test-Acc:0.8627 Train-Acc:0.752\n",
      "I:112 Test-Acc:0.8646 Train-Acc:0.76\n",
      "I:113 Test-Acc:0.8649 Train-Acc:0.766\n",
      "I:114 Test-Acc:0.8659 Train-Acc:0.752\n",
      "I:115 Test-Acc:0.868 Train-Acc:0.756\n",
      "I:116 Test-Acc:0.8648 Train-Acc:0.767\n",
      "I:117 Test-Acc:0.8662 Train-Acc:0.747\n",
      "I:118 Test-Acc:0.8669 Train-Acc:0.753\n",
      "I:119 Test-Acc:0.8694 Train-Acc:0.753\n",
      "I:120 Test-Acc:0.8692 Train-Acc:0.76\n",
      "I:121 Test-Acc:0.8658 Train-Acc:0.756\n",
      "I:122 Test-Acc:0.8666 Train-Acc:0.769\n",
      "I:123 Test-Acc:0.8692 Train-Acc:0.77\n",
      "I:124 Test-Acc:0.8681 Train-Acc:0.757\n",
      "I:125 Test-Acc:0.8705 Train-Acc:0.77\n",
      "I:126 Test-Acc:0.8706 Train-Acc:0.77\n",
      "I:127 Test-Acc:0.8684 Train-Acc:0.768\n",
      "I:128 Test-Acc:0.8664 Train-Acc:0.774\n",
      "I:129 Test-Acc:0.8666 Train-Acc:0.756\n",
      "I:130 Test-Acc:0.8705 Train-Acc:0.783\n",
      "I:131 Test-Acc:0.87 Train-Acc:0.775\n",
      "I:132 Test-Acc:0.8729 Train-Acc:0.769\n",
      "I:133 Test-Acc:0.8725 Train-Acc:0.776\n",
      "I:134 Test-Acc:0.8721 Train-Acc:0.772\n",
      "I:135 Test-Acc:0.8718 Train-Acc:0.765\n",
      "I:136 Test-Acc:0.8746 Train-Acc:0.777\n",
      "I:137 Test-Acc:0.8746 Train-Acc:0.77\n",
      "I:138 Test-Acc:0.8734 Train-Acc:0.778\n",
      "I:139 Test-Acc:0.873 Train-Acc:0.785\n",
      "I:140 Test-Acc:0.8732 Train-Acc:0.76\n",
      "I:141 Test-Acc:0.8727 Train-Acc:0.779\n",
      "I:142 Test-Acc:0.8754 Train-Acc:0.772\n",
      "I:143 Test-Acc:0.8729 Train-Acc:0.773\n",
      "I:144 Test-Acc:0.8758 Train-Acc:0.784\n",
      "I:145 Test-Acc:0.8732 Train-Acc:0.774\n",
      "I:146 Test-Acc:0.8743 Train-Acc:0.782\n",
      "I:147 Test-Acc:0.8762 Train-Acc:0.772\n",
      "I:148 Test-Acc:0.8755 Train-Acc:0.79\n",
      "I:149 Test-Acc:0.8751 Train-Acc:0.774\n",
      "I:150 Test-Acc:0.8749 Train-Acc:0.782\n",
      "I:151 Test-Acc:0.8744 Train-Acc:0.78\n",
      "I:152 Test-Acc:0.8765 Train-Acc:0.782\n",
      "I:153 Test-Acc:0.8738 Train-Acc:0.796\n",
      "I:154 Test-Acc:0.8753 Train-Acc:0.798\n",
      "I:155 Test-Acc:0.8767 Train-Acc:0.794\n",
      "I:156 Test-Acc:0.8746 Train-Acc:0.784\n",
      "I:157 Test-Acc:0.8769 Train-Acc:0.796\n",
      "I:158 Test-Acc:0.8758 Train-Acc:0.789\n",
      "I:159 Test-Acc:0.8764 Train-Acc:0.79\n",
      "I:160 Test-Acc:0.873 Train-Acc:0.791\n",
      "I:161 Test-Acc:0.8765 Train-Acc:0.797\n",
      "I:162 Test-Acc:0.8772 Train-Acc:0.789\n",
      "I:163 Test-Acc:0.8778 Train-Acc:0.781\n",
      "I:164 Test-Acc:0.8758 Train-Acc:0.799\n",
      "I:165 Test-Acc:0.8773 Train-Acc:0.785\n",
      "I:166 Test-Acc:0.8766 Train-Acc:0.796\n",
      "I:167 Test-Acc:0.8782 Train-Acc:0.803\n",
      "I:168 Test-Acc:0.8789 Train-Acc:0.794\n",
      "I:169 Test-Acc:0.8778 Train-Acc:0.794\n",
      "I:170 Test-Acc:0.8778 Train-Acc:0.8\n",
      "I:171 Test-Acc:0.8785 Train-Acc:0.791\n",
      "I:172 Test-Acc:0.8777 Train-Acc:0.787\n",
      "I:173 Test-Acc:0.8769 Train-Acc:0.781\n",
      "I:174 Test-Acc:0.8765 Train-Acc:0.786\n",
      "I:175 Test-Acc:0.8765 Train-Acc:0.793\n",
      "I:176 Test-Acc:0.8785 Train-Acc:0.796\n",
      "I:177 Test-Acc:0.879 Train-Acc:0.789\n",
      "I:178 Test-Acc:0.8763 Train-Acc:0.79\n",
      "I:179 Test-Acc:0.8774 Train-Acc:0.787\n",
      "I:180 Test-Acc:0.8766 Train-Acc:0.782\n",
      "I:181 Test-Acc:0.8803 Train-Acc:0.798\n",
      "I:182 Test-Acc:0.8781 Train-Acc:0.789\n",
      "I:183 Test-Acc:0.8795 Train-Acc:0.785\n",
      "I:184 Test-Acc:0.8791 Train-Acc:0.807\n",
      "I:185 Test-Acc:0.8778 Train-Acc:0.796\n",
      "I:186 Test-Acc:0.8783 Train-Acc:0.801\n",
      "I:187 Test-Acc:0.8778 Train-Acc:0.81\n",
      "I:188 Test-Acc:0.8771 Train-Acc:0.784\n",
      "I:189 Test-Acc:0.8776 Train-Acc:0.792\n",
      "I:190 Test-Acc:0.8784 Train-Acc:0.794\n",
      "I:191 Test-Acc:0.8787 Train-Acc:0.795\n",
      "I:192 Test-Acc:0.8803 Train-Acc:0.781\n",
      "I:193 Test-Acc:0.8798 Train-Acc:0.804\n",
      "I:194 Test-Acc:0.8779 Train-Acc:0.779\n",
      "I:195 Test-Acc:0.8788 Train-Acc:0.792\n",
      "I:196 Test-Acc:0.8764 Train-Acc:0.793\n",
      "I:197 Test-Acc:0.8792 Train-Acc:0.792\n",
      "I:198 Test-Acc:0.8798 Train-Acc:0.803\n",
      "I:199 Test-Acc:0.8788 Train-Acc:0.804\n",
      "I:200 Test-Acc:0.8793 Train-Acc:0.797\n",
      "I:201 Test-Acc:0.8764 Train-Acc:0.791\n",
      "I:202 Test-Acc:0.8801 Train-Acc:0.801\n",
      "I:203 Test-Acc:0.8814 Train-Acc:0.799\n",
      "I:204 Test-Acc:0.8806 Train-Acc:0.79\n",
      "I:205 Test-Acc:0.8799 Train-Acc:0.8\n",
      "I:206 Test-Acc:0.8803 Train-Acc:0.802\n",
      "I:207 Test-Acc:0.8782 Train-Acc:0.807\n",
      "I:208 Test-Acc:0.8818 Train-Acc:0.797\n",
      "I:209 Test-Acc:0.8793 Train-Acc:0.799\n",
      "I:210 Test-Acc:0.8789 Train-Acc:0.815\n",
      "I:211 Test-Acc:0.8791 Train-Acc:0.816\n",
      "I:212 Test-Acc:0.8793 Train-Acc:0.809\n",
      "I:213 Test-Acc:0.8814 Train-Acc:0.795\n",
      "I:214 Test-Acc:0.8798 Train-Acc:0.799\n",
      "I:215 Test-Acc:0.8805 Train-Acc:0.806\n",
      "I:216 Test-Acc:0.88 Train-Acc:0.808\n",
      "I:217 Test-Acc:0.8782 Train-Acc:0.801\n",
      "I:218 Test-Acc:0.8802 Train-Acc:0.814\n",
      "I:219 Test-Acc:0.8807 Train-Acc:0.8\n",
      "I:220 Test-Acc:0.8809 Train-Acc:0.798\n",
      "I:221 Test-Acc:0.8805 Train-Acc:0.82\n",
      "I:222 Test-Acc:0.8795 Train-Acc:0.794\n",
      "I:223 Test-Acc:0.8807 Train-Acc:0.806\n",
      "I:224 Test-Acc:0.8806 Train-Acc:0.808\n",
      "I:225 Test-Acc:0.8787 Train-Acc:0.802\n",
      "I:226 Test-Acc:0.8796 Train-Acc:0.81\n",
      "I:227 Test-Acc:0.8766 Train-Acc:0.805\n",
      "I:228 Test-Acc:0.8781 Train-Acc:0.792\n",
      "I:229 Test-Acc:0.8787 Train-Acc:0.809\n",
      "I:230 Test-Acc:0.8762 Train-Acc:0.802\n",
      "I:231 Test-Acc:0.8775 Train-Acc:0.811\n",
      "I:232 Test-Acc:0.8804 Train-Acc:0.814\n",
      "I:233 Test-Acc:0.8794 Train-Acc:0.804\n",
      "I:234 Test-Acc:0.8788 Train-Acc:0.801\n",
      "I:235 Test-Acc:0.8777 Train-Acc:0.795\n",
      "I:236 Test-Acc:0.8785 Train-Acc:0.808\n",
      "I:237 Test-Acc:0.8788 Train-Acc:0.803\n",
      "I:238 Test-Acc:0.8773 Train-Acc:0.813\n",
      "I:239 Test-Acc:0.8786 Train-Acc:0.808\n",
      "I:240 Test-Acc:0.8787 Train-Acc:0.803\n",
      "I:241 Test-Acc:0.8789 Train-Acc:0.812\n",
      "I:242 Test-Acc:0.8792 Train-Acc:0.804\n",
      "I:243 Test-Acc:0.8779 Train-Acc:0.815\n",
      "I:244 Test-Acc:0.8796 Train-Acc:0.811\n",
      "I:245 Test-Acc:0.8798 Train-Acc:0.806\n",
      "I:246 Test-Acc:0.88 Train-Acc:0.803\n",
      "I:247 Test-Acc:0.8776 Train-Acc:0.795\n",
      "I:248 Test-Acc:0.8798 Train-Acc:0.803\n",
      "I:249 Test-Acc:0.8799 Train-Acc:0.805\n",
      "I:250 Test-Acc:0.8789 Train-Acc:0.807\n",
      "I:251 Test-Acc:0.8784 Train-Acc:0.804\n",
      "I:252 Test-Acc:0.8792 Train-Acc:0.806\n",
      "I:253 Test-Acc:0.8777 Train-Acc:0.796\n",
      "I:254 Test-Acc:0.8785 Train-Acc:0.821\n",
      "I:255 Test-Acc:0.8794 Train-Acc:0.81\n",
      "I:256 Test-Acc:0.8783 Train-Acc:0.816\n",
      "I:257 Test-Acc:0.8777 Train-Acc:0.812\n",
      "I:258 Test-Acc:0.8791 Train-Acc:0.812\n",
      "I:259 Test-Acc:0.878 Train-Acc:0.813\n",
      "I:260 Test-Acc:0.8784 Train-Acc:0.82\n",
      "I:261 Test-Acc:0.8792 Train-Acc:0.821\n",
      "I:262 Test-Acc:0.8781 Train-Acc:0.823\n",
      "I:263 Test-Acc:0.8788 Train-Acc:0.816\n",
      "I:264 Test-Acc:0.8793 Train-Acc:0.82\n",
      "I:265 Test-Acc:0.8781 Train-Acc:0.829\n",
      "I:266 Test-Acc:0.8795 Train-Acc:0.809\n",
      "I:267 Test-Acc:0.875 Train-Acc:0.806\n",
      "I:268 Test-Acc:0.8795 Train-Acc:0.813\n",
      "I:269 Test-Acc:0.88 Train-Acc:0.816\n",
      "I:270 Test-Acc:0.8796 Train-Acc:0.819\n",
      "I:271 Test-Acc:0.8802 Train-Acc:0.809\n",
      "I:272 Test-Acc:0.8804 Train-Acc:0.811\n",
      "I:273 Test-Acc:0.8779 Train-Acc:0.808\n",
      "I:274 Test-Acc:0.8816 Train-Acc:0.82\n",
      "I:275 Test-Acc:0.8792 Train-Acc:0.822\n",
      "I:276 Test-Acc:0.8791 Train-Acc:0.817\n",
      "I:277 Test-Acc:0.8769 Train-Acc:0.814\n",
      "I:278 Test-Acc:0.8785 Train-Acc:0.807\n",
      "I:279 Test-Acc:0.8778 Train-Acc:0.817\n",
      "I:280 Test-Acc:0.8794 Train-Acc:0.82\n",
      "I:281 Test-Acc:0.8804 Train-Acc:0.824\n",
      "I:282 Test-Acc:0.8779 Train-Acc:0.812\n",
      "I:283 Test-Acc:0.8784 Train-Acc:0.816\n",
      "I:284 Test-Acc:0.877 Train-Acc:0.817\n",
      "I:285 Test-Acc:0.8767 Train-Acc:0.826\n",
      "I:286 Test-Acc:0.8774 Train-Acc:0.816\n",
      "I:287 Test-Acc:0.8774 Train-Acc:0.804\n",
      "I:288 Test-Acc:0.8774 Train-Acc:0.814\n",
      "I:289 Test-Acc:0.8776 Train-Acc:0.806\n",
      "I:290 Test-Acc:0.8787 Train-Acc:0.822\n",
      "I:291 Test-Acc:0.8781 Train-Acc:0.817\n",
      "I:292 Test-Acc:0.878 Train-Acc:0.823\n",
      "I:293 Test-Acc:0.877 Train-Acc:0.825\n",
      "I:294 Test-Acc:0.8759 Train-Acc:0.826\n",
      "I:295 Test-Acc:0.8769 Train-Acc:0.824\n",
      "I:296 Test-Acc:0.8781 Train-Acc:0.821\n",
      "I:297 Test-Acc:0.8794 Train-Acc:0.81\n",
      "I:298 Test-Acc:0.8791 Train-Acc:0.81\n",
      "I:299 Test-Acc:0.8772 Train-Acc:0.825"
     ]
    }
   ],
   "source": [
    "#4 Page 221-223 - We are investigating convolutional neural networks\n",
    "\n",
    "for j in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_start, batch_end = ((i*batch_size), ((i+1)*batch_size))\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
    "        layer_0.shape\n",
    "        \n",
    "        sects = list()\n",
    "        for row_start in range(layer_0.shape[1] - kernel_rows):\n",
    "            for col_start in range(layer_0.shape[2] - kernel_rows):\n",
    "                sect = get_image_section(layer_0,\n",
    "                                        row_start,\n",
    "                                        row_start+kernel_rows,\n",
    "                                        col_start,\n",
    "                                        col_start+kernel_cols)\n",
    "                sects.append(sect)\n",
    "        \n",
    "        expanded_input = np.concatenate(sects, axis=1)\n",
    "        es = expanded_input.shape\n",
    "        flattened_input = expanded_input.reshape(es[0]*es[1], -1)\n",
    "        \n",
    "        kernel_output = flattened_input.dot(kernels)\n",
    "        layer_1 = tanh(kernel_output.reshape(es[0],-1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            labelset = labels[batch_start+k:batch_start+k+1]\n",
    "            _inc = int(np.argmax(layer_2[k:k+1]) == \n",
    "                      np.argmax(labelset))\n",
    "            correct_cnt += _inc\n",
    "            \n",
    "        layer_2_delta = (labels[batch_start:batch_end] - layer_2) \\\n",
    "                        / (batch_size * layer_2.shape[0])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * \\\n",
    "                        tanh2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        l1d_reshape = layer_1_delta.reshape(kernel_output.shape)\n",
    "        k_update = flattened_input.T.dot(l1d_reshape)\n",
    "        kernels -= alpha * k_update\n",
    "        \n",
    "    \n",
    "    test_correct_cnt = 0\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
    "        layer_0.shape\n",
    "        \n",
    "        sects = list()\n",
    "        for row_start in range(layer_0.shape[1] - kernel_rows):\n",
    "            for col_start in range(layer_0.shape[2] - kernel_rows):\n",
    "                sect = get_image_section(layer_0,\n",
    "                                        row_start,\n",
    "                                        row_start+kernel_rows,\n",
    "                                        col_start,\n",
    "                                        col_start+kernel_cols)\n",
    "                sects.append(sect)\n",
    "        \n",
    "        expanded_input = np.concatenate(sects, axis=1)\n",
    "        es = expanded_input.shape\n",
    "        flattened_input = expanded_input.reshape(es[0]*es[1], -1)\n",
    "        \n",
    "        kernel_output = flattened_input.dot(kernels)\n",
    "        layer_1 = tanh(kernel_output.reshape(es[0],-1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        test_correct_cnt += int(np.argmax(layer_2) == \n",
    "                              np.argmax(test_labels[i:i+1]))\n",
    "    \n",
    "    if (j % 1 == 0):\n",
    "        sys.stdout.write(\"\\n\" + \\\n",
    "        \"I:\" + str(j) + \\\n",
    "        \" Test-Acc:\" + str(test_correct_cnt/float(len(test_images)))+\\\n",
    "        \" Train-Acc:\" + str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some preprocessing work not in the book\n",
    "filenames = ['reviews #1.txt', 'reviews #2.txt']\n",
    "with open('reviews.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 214 - preprocessing\n",
    "\n",
    "import sys\n",
    "\n",
    "f = open('reviews.txt')\n",
    "raw_reviews = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open('labels.txt')\n",
    "raw_labels = f.readlines()\n",
    "f.close()\n",
    "\n",
    "tokens = list(map(lambda x:set(x.split(' ')), raw_reviews))\n",
    "\n",
    "vocab = set()\n",
    "for sent in tokens:\n",
    "    for word in sent:\n",
    "        if (len(word) > 0):\n",
    "            vocab.add(word)\n",
    "vocab = list(vocab)\n",
    "\n",
    "word2index = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "    \n",
    "input_dataset = list()\n",
    "for sent in tokens:\n",
    "    sent_indices = list()\n",
    "    for word in sent:\n",
    "        try:\n",
    "            sent_indices.append(word2index[word])\n",
    "        except:\n",
    "            ''\n",
    "    input_dataset.append(list(set(sent_indices)))\n",
    "    \n",
    "target_dataset = list()\n",
    "for label in raw_labels:\n",
    "    if label == 'positive\\n':\n",
    "        target_dataset.append(1)\n",
    "    else:\n",
    "        target_dataset.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0 Progress:95.95% Training Accuracy:0.7971654856190079%%\n",
      "Iter:1 Progress:95.95% Training Accuracy:0.8195211402613098%\n",
      "Test Accuracy:0.843\n"
     ]
    }
   ],
   "source": [
    "# Page 216\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "alpha, iterations = (0.01, 2)\n",
    "hidden_size = 100\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((len(vocab),hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,1)) - 0.1\n",
    "\n",
    "correct,total = (0,0)\n",
    "for iter in range(iterations):\n",
    "    for i in range(len(input_dataset)-1000):\n",
    "        \n",
    "        x, y = (input_dataset[i], target_dataset[i])\n",
    "        layer_1 = sigmoid(np.sum(weights_0_1[x], axis=0))\n",
    "        layer_2 = sigmoid(np.dot(layer_1, weights_1_2))\n",
    "        \n",
    "        layer_2_delta = layer_2 - y\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\n",
    "        \n",
    "        weights_0_1[x] -= layer_1_delta * alpha\n",
    "        weights_1_2 -= np.outer(layer_1, layer_2_delta) * alpha\n",
    "        \n",
    "        if(np.abs(layer_2_delta) < 0.5):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        if(i % 10 == 9):\n",
    "            progress = str(i/float(len(input_dataset)))\n",
    "            sys.stdout.write('\\rIter:'+str(iter)\\\n",
    "                            +' Progress:'+progress[2:4]\\\n",
    "                            +'.'+progress[4:6]\\\n",
    "                            +'% Training Accuracy:'\\\n",
    "                            + str(correct/float(total)) + '%')\n",
    "    print()\n",
    "correct, total = (0,0)\n",
    "for i in range(len(input_dataset)-1000,len(input_dataset)):\n",
    "    x = input_dataset[i]\n",
    "    y = target_dataset[i]\n",
    "    \n",
    "    layer_1 = sigmoid(np.sum(weights_0_1[x],axis=0))\n",
    "    layer_2 = sigmoid(np.dot(layer_1,weights_1_2))\n",
    "    \n",
    "    if(np.abs(layer_2 - y) < 0.5):\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(\"Test Accuracy:\" + str(correct / float(total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substitution of missing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 243 - preprocessing step\n",
    "import sys,random,math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "f = open('reviews.txt')\n",
    "raw_reviews = f.readlines()\n",
    "f.close()\n",
    "\n",
    "tokens = list(map(lambda x:(x.split(\" \")),raw_reviews))\n",
    "wordcnt = Counter()\n",
    "for sent in tokens:\n",
    "    for word in sent:\n",
    "        wordcnt[word] -= 1\n",
    "vocab = list(set(map(lambda x:x[0],wordcnt.most_common())))\n",
    "                                    \n",
    "word2index = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "                                    \n",
    "  \n",
    "concatenated = list()\n",
    "input_dataset = list()\n",
    "for sent in tokens:\n",
    "    sent_indices = list()\n",
    "    for word in sent:\n",
    "        try:\n",
    "            sent_indices.append(word2index[word])\n",
    "            concatenated.append(word2index[word])\n",
    "        except:\n",
    "            \"\"\n",
    "    input_dataset.append(sent_indices)\n",
    "concatenated = np.array(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.9999799991999689 [('terrible', -0.0), ('horrible', -2.52559168953348), ('fantastic', -3.93465090925655), ('bad', -4.051182051722724), ('brilliant', -4.154160608588459), ('pathetic', -4.211284441468548), ('dreadful', -4.283776633630338), ('poor', -4.380962727928457), ('magnificent', -4.382881495844147), ('great', -4.401655404772276)]5)]58)]9)]]5)])])]]]]])])][('terrible', -0.0), ('horrible', -2.6096546786637247), ('bad', -3.767183518137911), ('fantastic', -3.875075043677378), ('brilliant', -3.991796014301944), ('pathetic', -4.10884763219456), ('dreadful', -4.243173950738017), ('stupid', -4.338180291179504), ('poor', -4.344969143714373), ('great', -4.373188116606074)]\n"
     ]
    }
   ],
   "source": [
    "# Page 243-244\n",
    "\n",
    "random.shuffle(input_dataset)\n",
    "alpha, iterations = (0.05, 2)\n",
    "hidden_size, window, negative = (50, 2, 5)\n",
    "\n",
    "weights_0_1 = (np.random.rand(len(vocab),hidden_size) - 0.5) * 0.2\n",
    "weights_1_2 = np.random.rand(len(vocab),hidden_size) * 0.2\n",
    "\n",
    "layer_2_target = np.zeros(negative+1)\n",
    "layer_2_target[0] = 1\n",
    "\n",
    "def similar(target='beautiful'):\n",
    "    target_index = word2index[target]\n",
    "    \n",
    "    scores = Counter()\n",
    "    for word, index in word2index.items():\n",
    "        raw_difference = weights_0_1[index] - (weights_0_1[target_index])\n",
    "        squared_difference = raw_difference * raw_difference\n",
    "        scores[word] = - math.sqrt(sum(squared_difference))\n",
    "    return scores.most_common(10)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "for rev_i, review in enumerate(input_dataset * iterations):\n",
    "    for target_i in range(len(review)):\n",
    "\n",
    "        target_samples = [review[target_i]]+list(concatenated\\\n",
    "            [(np.random.rand(negative)*len(concatenated)).astype('int').tolist()])\n",
    "\n",
    "        left_context = review[max(0,target_i-window):target_i]\n",
    "        right_context = review[target_i+1:min(len(review),target_i+window)]\n",
    "\n",
    "        layer_1 = np.mean(weights_0_1[left_context+right_context],axis=0)\n",
    "        layer_2 = sigmoid(layer_1.dot(weights_1_2[target_samples].T))\n",
    "        layer_2_delta = layer_2 - layer_2_target\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2[target_samples])\n",
    "\n",
    "        weights_0_1[left_context+right_context] -= layer_1_delta * alpha\n",
    "        weights_1_2[target_samples] -= np.outer(layer_2_delta,layer_1)*alpha\n",
    "\n",
    "    if(rev_i % 250 == 0):\n",
    "        sys.stdout.write('\\rProgress:'+str(rev_i/float(len(input_dataset)\n",
    "            *iterations)) + \" \" + str(similar('terrible')))\n",
    "    sys.stdout.write('\\rProgress:'+str(rev_i/float(len(input_dataset)\n",
    "            *iterations)))\n",
    "        \n",
    "print(similar('terrible'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks that write like Shakespeare: recurrent layers for variable-length data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i don  t know why i like this movie so w',\n",
       " 'this movie is so bad  i knew how it ends',\n",
       " 'probably new zealands worst movie ever m']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Page 256\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "norms = np.sum(weights_0_1 * weights_0_1, axis=1)\n",
    "norms.resize(norms.shape[0], 1)\n",
    "normed_weights = weights_0_1 * norms\n",
    "\n",
    "def make_sent_vect(words):\n",
    "    indices = list(map(lambda x:word2index[x], \\\n",
    "                filter(lambda x: x in word2index, words)))\n",
    "    return np.mean(normed_weights[indices], axis=0)\n",
    "\n",
    "reviews2vectors = list()\n",
    "for review in tokens:\n",
    "    reviews2vectors.append(make_sent_vect(review))\n",
    "reviews2vectors = np.array(reviews2vectors)\n",
    "\n",
    "def most_similar_reviews(review):\n",
    "    v = make_sent_vect(review)\n",
    "    scores = Counter()\n",
    "    for i, val in enumerate(reviews2vectors.dot(v)):\n",
    "        scores[i] = val\n",
    "    most_similar = list()\n",
    "    for idx, score in scores.most_common(3):\n",
    "        most_similar.append(raw_reviews[idx][0:40])\n",
    "    return most_similar\n",
    "\n",
    "most_similar_reviews(['boring','awful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[1. 2. 3.]\n",
      "[0.1 0.2 0.3]\n",
      "[-1.  -0.5  0. ]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Page 262-263 identity matrix Practice\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([0.1, 0.2, 0.3])\n",
    "c = np.array([-1, -0.5, 0])\n",
    "d = np.array([0, 0, 0])\n",
    "\n",
    "identity = np.eye(3)\n",
    "print(identity)\n",
    "\n",
    "print(a.dot(identity))\n",
    "print(b.dot(identity))\n",
    "print(c.dot(identity))\n",
    "print(d.dot(identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 15 17]\n",
      "[13. 15. 17.]\n"
     ]
    }
   ],
   "source": [
    "# Page 263\n",
    "\n",
    "this = np.array([2, 4, 6])\n",
    "movie = np.array([10, 10, 10])\n",
    "rocks = np.array([1, 1, 1])\n",
    "\n",
    "print(this + movie + rocks)\n",
    "print((this.dot(identity) + movie).dot(identity) + rocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 267\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x_):\n",
    "    x = np.atleast_2d(x_)\n",
    "    temp = .()\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "word_vects = {}\n",
    "word_vects['yankees'] = np.array([[0., 0., 0.]])\n",
    "word_vects['bears'] = np.array([[0., 0., 0.]])\n",
    "word_vects['braves'] = np.array([[0., 0., 0.]])\n",
    "word_vects['red'] = np.array([[0., 0., 0.]])\n",
    "word_vects['sox'] = np.array([[0., 0., 0.]])\n",
    "word_vects['lose'] = np.array([[0., 0., 0.]])\n",
    "word_vects['defeat'] = np.array([[0., 0., 0.]])\n",
    "word_vects['beat'] = np.array([[0., 0., 0.]])\n",
    "word_vects['tie'] = np.array([[0., 0., 0.]])\n",
    "\n",
    "sent2output = np.random.rand(3, len(word_vects))\n",
    "\n",
    "identity = np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 267 - creating layers for forward prop.\n",
    "\n",
    "layer_0 = word_vects['red']\n",
    "layer_1 = layer_0.dot(identity) + word_vects['sox']\n",
    "layer_2 = layer_1.dot(identity) + word_vects['defeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": " ",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
